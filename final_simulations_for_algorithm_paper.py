# -*- coding: utf-8 -*-
"""final simulations for algorithm paper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MM4TxrOZ3jI9VwoGzg2LaCuW276uuqe_
"""

# Cow Herd Simulation with Role-Based Goal Attraction + Learning Curve Plot

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.patches import Circle
from matplotlib.lines import Line2D
from IPython.display import HTML

# --- Parameters ---
NUM_COWS = 30
TIMESTEPS = 200
FIELD_SIZE = 100
SENSOR_RANGE = 12
FENCE_BUFFER = 5

# Stimulus parameters
f_opt = 8000
sigma_f = 1500
A = 85
A_50 = 70
s = 0.3
gamma = 1.0
t_50 = 10
lambda_h = 0.05
k1 = 1.0
k2 = 7.0
theta = 0.3  # Updated to match description

NOISE_TYPE = 'tone'
NOISE_MAP = {'tone': 1.0, 'clanging': 1.1, 'shouting': 1.3}

LEADER_IDS = [0, 1]
DOMINANT_IDS = [2, 3]
SHY_IDS = [28, 29]

# --- Equations ---
def F(f): return np.exp(-((f - f_opt)**2) / (2 * sigma_f**2))
def S(A): return 1 / (1 + np.exp(-s * (A - A_50)))
def L(t): return 1 / (1 + np.exp(-gamma * (t - t_50)))
def H(t): return np.exp(-lambda_h * t)
def N(n): return NOISE_MAP.get(n, 1.0)
def P_turn(SA, Ff, Lt, g=1.0): return 1 / (1 + np.exp(-g * k2 * (SA * Ff * Lt - theta)))

# --- Simulation ---
def simulate():
    np.random.seed(42)
    positions = np.random.normal(loc=50, scale=5, size=(NUM_COWS, 2))
    positions = np.clip(positions, FENCE_BUFFER + 1, FIELD_SIZE - FENCE_BUFFER - 1)
    headings = np.random.rand(NUM_COWS, 2) - 0.5
    headings /= np.linalg.norm(headings, axis=1, keepdims=True)
    personalities = np.random.beta(6, 2, NUM_COWS) * 0.4 + 0.9
    time_near_fence = np.zeros(NUM_COWS)

    colors = ['green' if i in LEADER_IDS else
              'red' if i in DOMINANT_IDS else
              'purple' if i in SHY_IDS else 'blue' for i in range(NUM_COWS)]

    goal = np.array([60, 60])
    trajectory = []
    L_vals = []

    f = 8000
    for t in range(TIMESTEPS):
        SA, Ff, Lt, Ht, Nn = S(A), F(f), L(t), H(t), N(NOISE_TYPE)
        M_t = k1 * Ff * SA * Ht * Nn
        L_vals.append(Lt)

        new_positions = positions.copy()
        new_headings = headings.copy()

        for i in range(NUM_COWS):
            neighbors = [j for j in range(NUM_COWS) if i != j and np.linalg.norm(positions[i] - positions[j]) < SENSOR_RANGE]
            sep, align, coh = np.zeros(2), np.zeros(2), np.zeros(2)
            turn_count = 0

            for j in neighbors:
                diff = positions[i] - positions[j]
                dist = np.linalg.norm(diff)
                if dist > 0:
                    sep += diff / dist
                    align += headings[j]
                    coh += positions[j]
                if np.dot(headings[j], headings[i]) < 0:
                    turn_count += 1

            g = 1.3 if neighbors and turn_count > len(neighbors) // 2 else 1.0

            if neighbors:
                sep /= len(neighbors)
                align /= len(neighbors)
                coh = (coh / len(neighbors)) - positions[i]

            goal_vec = goal - positions[i]
            if np.linalg.norm(goal_vec) > 0:
                goal_vec /= np.linalg.norm(goal_vec)

            # Role-based attraction: leaders are more strongly pulled
            goal_weight = 3.0 if i in LEADER_IDS else 1.8

            move_vector = (
                1.5 * sep +
                1.0 * align +
                2.0 * coh +
                goal_weight * goal_vec +
                1.8 * headings[i] * M_t
            )

            if np.linalg.norm(move_vector) > 0:
                move_vector /= np.linalg.norm(move_vector)

            if P_turn(SA, Ff, Lt, g) > np.random.rand():
                move_vector = -move_vector

            move_vector *= personalities[i]

            x, y = positions[i]
            fx, fy = 0, 0
            if x < FENCE_BUFFER: fx = (FENCE_BUFFER - x) / FENCE_BUFFER
            elif x > FIELD_SIZE - FENCE_BUFFER: fx = -(x - (FIELD_SIZE - FENCE_BUFFER)) / FENCE_BUFFER
            if y < FENCE_BUFFER: fy = (FENCE_BUFFER - y) / FENCE_BUFFER
            elif y > FIELD_SIZE - FENCE_BUFFER: fy = -(y - (FIELD_SIZE - FENCE_BUFFER)) / FENCE_BUFFER

            near_fence = any([
                x < FENCE_BUFFER,
                x > FIELD_SIZE - FENCE_BUFFER,
                y < FENCE_BUFFER,
                y > FIELD_SIZE - FENCE_BUFFER
            ])
            time_near_fence[i] = time_near_fence[i] + 1 if near_fence else 0
            if time_near_fence[i] > 5:
                move_vector = -move_vector
                time_near_fence[i] = 0

            fence_vector = np.array([fx, fy])
            velocity = 0.8 * headings[i] + 0.2 * (move_vector + fence_vector)
            if np.linalg.norm(velocity) > 0:
                velocity /= np.linalg.norm(velocity)

            new_positions[i] += velocity
            new_headings[i] = velocity

        positions = np.clip(new_positions, 0, FIELD_SIZE)
        headings = new_headings
        trajectory.append((positions.copy(), colors))

    return trajectory, goal, L_vals

# --- Animation ---
def animate_trajectory(trajectory, goal):
    fig, ax = plt.subplots(figsize=(9, 9))
    scat = ax.scatter([], [], s=40)

    ax.set_xlim(-10, FIELD_SIZE + 10)
    ax.set_ylim(-10, FIELD_SIZE + 10)

    ax.tick_params(axis='both', which='major', labelsize=16)

    ax.set_xticks([])
    ax.set_yticks([])
    ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)

    ax.axvspan(0, FENCE_BUFFER, facecolor='red', alpha=0.1)
    ax.axvspan(FIELD_SIZE - FENCE_BUFFER, FIELD_SIZE, facecolor='red', alpha=0.1)
    ax.axhspan(0, FENCE_BUFFER, facecolor='red', alpha=0.1)
    ax.axhspan(FIELD_SIZE - FENCE_BUFFER, FIELD_SIZE, facecolor='red', alpha=0.1)

    ax.axvline(x=FENCE_BUFFER, color='red', linestyle='--')
    ax.axvline(x=FIELD_SIZE - FENCE_BUFFER, color='red', linestyle='--')
    ax.axhline(y=FENCE_BUFFER, color='red', linestyle='--')
    ax.axhline(y=FIELD_SIZE - FENCE_BUFFER, color='red', linestyle='--')

    ax.add_patch(Circle(goal, radius=3, color='orange', alpha=0.3))

    legend_elements = [
        Line2D([0], [0], marker='o', color='w', label='Leader', markerfacecolor='green', markersize=14),
        Line2D([0], [0], marker='o', color='w', label='Dominant', markerfacecolor='red', markersize=14),
        Line2D([0], [0], marker='o', color='w', label='Shy', markerfacecolor='purple', markersize=14),
        Line2D([0], [0], marker='o', color='w', label='Normal', markerfacecolor='blue', markersize=14),
        Line2D([0], [0], marker='o', color='orange', label='Attraction Goal', markerfacecolor='orange', markersize=16, alpha=0.3),
    ]
    ax.legend(handles=legend_elements, loc='upper right', fontsize=16)


    def update(frame):
        pos, col = trajectory[frame]
        scat.set_offsets(pos)
        scat.set_facecolor(col)
        return scat,

    ani = animation.FuncAnimation(fig, update, frames=len(trajectory), interval=150, blit=True)
    return ani.to_jshtml(), ani

# --- Run ---
trajectory, goal, L_vals = simulate()
html_anim, ani = animate_trajectory(trajectory, goal)
HTML(html_anim)

# Save animation (optional)
ani.save("SV1_updated.mp4", writer="ffmpeg", fps=6)

#BEST
from google.colab import files
import matplotlib as mpl
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from moviepy.editor import VideoFileClip, clips_array
from IPython.display import HTML

mpl.rcParams['xtick.labelsize']  = 22   # x‑tick labels
mpl.rcParams['ytick.labelsize']  = 22   # y‑tick labels

# Use known video path or change if needed
video_path = "/content/cow aerial 2 low.mov"
clip = VideoFileClip(video_path)
VIDEO_DURATION = clip.duration
FPS = int(clip.fps)
TIMESTEPS = int(VIDEO_DURATION * FPS)
video_size = clip.size

NUM_COWS = 120
FIELD_SIZE = 200
MIN_SPEED = 0.2
MAX_SPEED = 1.0
VISUAL_RANGE = 12
PROTECTED_RANGE = 3

def generate_directional_initial_positions(num_cows, field_size):
    np.random.seed(42)
    x = np.random.normal(loc=70, scale=25, size=num_cows)
    y = np.random.normal(loc=100, scale=30, size=num_cows)
    x = np.clip(x, 0, field_size)
    y = np.clip(y, 0, field_size)
    return np.stack([x, y], axis=1)

def simulate_cloud_herd_behavior_v9(
    num_cows=120,
    field_size=200,
    timesteps=2040,
    fps=60,
    turn_start_sec=7,
    pause_probability=0.05,
    visual_range=16,
    protected_range=4
):
    import numpy as np

    np.random.seed(42)
    positions = generate_directional_initial_positions(num_cows, field_size)
    initial_angle = np.radians(12)
    velocities = np.array([
        [np.cos(initial_angle), np.sin(initial_angle)]
        for _ in range(num_cows)
    ]) * 0.3

    herd_drift = np.mean(velocities, axis=0)
    turn_start_frame = int(fps * turn_start_sec)
    final_goal = np.array([20.0, 20.0])

    wander_angles = np.random.uniform(-10, 10, size=num_cows)
    fan_out_bias = np.random.uniform(0.8, 1.2, size=num_cows)
    paused = np.random.rand(num_cows) < pause_probability
    trajectory = []

    for t in range(timesteps):
        new_positions = positions.copy()
        new_velocities = velocities.copy()

        # Goal steering (start after 7s)
        if t > turn_start_frame:
            turn_duration = 800
            progress = min((t - turn_start_frame) / turn_duration, 1.0)
            target_vector = final_goal - np.mean(positions, axis=0)
            target_vector /= (np.linalg.norm(target_vector) + 1e-4)
            directional_turn = target_vector * 0.15 * progress
        else:
            directional_turn = np.zeros(2)

        # Fanning behavior
        fan_progress = max(0, (t - 1200) / (2040 - 1200))
        max_fan_angle = 25
        fan_turns = np.radians(fan_out_bias * max_fan_angle * fan_progress)

        for i in range(num_cows):
            pos_i = positions[i]
            vel_i = velocities[i]

            repel_force = np.zeros(2)
            align_force = np.zeros(2)
            align_count = 0

            for j in range(num_cows):
                if i == j:
                    continue
                offset = positions[j] - pos_i
                dist = np.linalg.norm(offset)

                if dist < protected_range:
                    repel_force -= 2.8 * offset / (dist + 1e-4)
                elif dist < visual_range:
                    align_force += velocities[j]
                    align_count += 1

            if align_count > 0:
                align_force /= align_count
                align_force = align_force / (np.linalg.norm(align_force) + 1e-4)
                align_force *= 0.05

            # Cow-specific wander bias
            wander_angle_rad = np.radians(wander_angles[i])
            wander_rotation = np.array([
                [np.cos(wander_angle_rad), -np.sin(wander_angle_rad)],
                [np.sin(wander_angle_rad),  np.cos(wander_angle_rad)]
            ])
            wander_bias = wander_rotation @ herd_drift * 0.05

            # Directional fan curve
            fan_rot = np.array([
                [np.cos(fan_turns[i]), -np.sin(fan_turns[i])],
                [np.sin(fan_turns[i]),  np.cos(fan_turns[i])]
            ])
            fanned_turn = fan_rot @ directional_turn

            # ---------------------------
            # UPDATED EXIT + DISPERSAL
            # ---------------------------
            exit_phase = max(0, (t - 1260) / (2040 - 1260))
            exit_drift_vector = np.array([-0.035, -0.055]) * exit_phase
            repel_force *= (1.0 - 0.7 * exit_phase)
            align_force *= (1.0 - 0.5 * exit_phase)
            spread_force = np.zeros(2)
            goal_damp = (1.0 - 1.0 * exit_phase)

            # Combine all forces
            raw_velocity = (
                repel_force * 0.15 +
                align_force +
                wander_bias +
                fanned_turn * goal_damp +
                spread_force +
                exit_drift_vector
            )

            # Smooth velocity (momentum-like behavior)
            new_vel = 0.85 * vel_i + 0.15 * raw_velocity

            # Speed control
            speed = np.linalg.norm(new_vel)
            if speed < MIN_SPEED:
                new_vel = (new_vel / (speed + 1e-8)) * MIN_SPEED
            elif speed > MAX_SPEED:
                new_vel = (new_vel / speed) * MAX_SPEED

            # Grazing pauses (fade over time)
            pause_decay = max(0.5, 1 - (t / timesteps))
            dynamic_pause_prob = pause_probability * pause_decay
            if paused[i]:
                new_vel *= 0.6
                if np.random.rand() < 0.002:
                    paused[i] = False
            else:
                if np.random.rand() < dynamic_pause_prob:
                    paused[i] = True

            # Update wander direction
            wander_angles[i] += np.random.normal(scale=0.4)
            wander_angles[i] = np.clip(wander_angles[i], -25, 25)

            new_positions[i] += new_vel
            new_velocities[i] = new_vel

        # Let cows exit freely after 28s
        if t < 1680:
            positions = np.clip(new_positions, 0, field_size)
        else:
            positions = new_positions

        velocities = new_velocities
        trajectory.append(positions.copy())

    return trajectory


def animate_trajectory(trajectory):
    fig, ax = plt.subplots(figsize=(10, 10))
    scat = ax.scatter([], [], c='blue', s=25)
    ax.set_xlim(0, FIELD_SIZE)
    ax.set_ylim(0, FIELD_SIZE)
    ax.set_aspect('equal')

    def update(frame):
        scat.set_offsets(trajectory[frame])
        return scat,

    ani = animation.FuncAnimation(fig, update, frames=len(trajectory), interval=1000/FPS, blit=True)
    ani.save("boid_simulation.mp4", writer="ffmpeg", fps=FPS)
    plt.close()

def create_side_by_side():
    sim_clip = VideoFileClip("boid_simulation.mp4").resize(video_size)
    real_clip = VideoFileClip(video_path).resize(video_size)
    combined = clips_array([[real_clip, sim_clip]])
    combined.write_videofile("side_by_side_comparison.mp4", fps=FPS)

trajectory = simulate_cloud_herd_behavior_v9()
animate_trajectory(trajectory)
create_side_by_side()
files.download("side_by_side_comparison.mp4")

#BEST

pip install moviepy opencv-python numpy scipy matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter

# Load CSVs
aerial_df = pd.read_csv("aerial_metrics.csv")
boid_df = pd.read_csv("boid_metrics.csv")

# Ensure equal length
min_len = min(len(aerial_df), len(boid_df))
aerial_df = aerial_df.iloc[:min_len].reset_index(drop=True)
boid_df = boid_df.iloc[:min_len].reset_index(drop=True)

# Normalize centroid positions
aerial_centroid_x = aerial_df["centroid_x"] - aerial_df["centroid_x"].iloc[0]
aerial_centroid_y = aerial_df["centroid_y"] - aerial_df["centroid_y"].iloc[0]
boid_centroid_x = boid_df["centroid_x"] - boid_df["centroid_x"].iloc[0]
boid_centroid_y = boid_df["centroid_y"] - boid_df["centroid_y"].iloc[0]

# Smoothing helper
def smooth_safe(arr, window=31, poly=3):
    arr = np.array(arr)
    mask = ~np.isnan(arr)
    if np.sum(mask) > window:
        arr[mask] = savgol_filter(arr[mask], window, poly)
    return arr

# Apply smoothing
aerial_disp_smooth = smooth_safe(aerial_df["dispersion"])
boid_disp_smooth = smooth_safe(boid_df["dispersion"])
aerial_dir_smooth = smooth_safe(aerial_df["direction_deg"])
boid_dir_smooth = smooth_safe(boid_df["direction_deg"])

# Frame index
time = np.arange(min_len)

# Plot
plt.figure(figsize=(12, 10))

# Dispersion
plt.subplot(3, 1, 1)
plt.plot(time, boid_disp_smooth, label="Sim Dispersion (smoothed)", color="orange")
plt.plot(time, aerial_disp_smooth, label="Real Dispersion (smoothed)", color="blue")
plt.title("Smoothed Herd Dispersion Over Time")
plt.ylabel("Avg Pairwise Distance")
plt.legend()

# Centroid Position
plt.subplot(3, 1, 2)
plt.plot(time, boid_centroid_x, label="Sim X (norm)", color="orange")
plt.plot(time, boid_centroid_y, label="Sim Y (norm)", color="orange", linestyle="--")
plt.plot(time, aerial_centroid_x, label="Real X (norm)", color="blue")
plt.plot(time, aerial_centroid_y, label="Real Y (norm)", color="blue", linestyle="--")
plt.title("Normalized Centroid Position Over Time")
plt.ylabel("Centroid Position (relative)")
plt.legend()

# Direction
plt.subplot(3, 1, 3)
plt.plot(time, boid_dir_smooth, label="Sim Direction (smoothed)", color="orange")
plt.plot(time, aerial_dir_smooth, label="Real Direction (smoothed)", color="blue")
plt.title("Smoothed Herd Directionality Over Time")
plt.xlabel("Frame Index")
plt.ylabel("Angle (degrees)")
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from scipy.stats import pearsonr
from scipy.signal import savgol_filter

# Load CSVs
aerial_df = pd.read_csv("aerial_metrics.csv")
boid_df = pd.read_csv("boid_metrics.csv")

# Trim to same length
min_len = min(len(aerial_df), len(boid_df))
aerial_df = aerial_df.iloc[:min_len].reset_index(drop=True)
boid_df = boid_df.iloc[:min_len].reset_index(drop=True)

# Normalize centroids
aerial_cx = aerial_df["centroid_x"] - aerial_df["centroid_x"].iloc[0]
aerial_cy = aerial_df["centroid_y"] - aerial_df["centroid_y"].iloc[0]
boid_cx = boid_df["centroid_x"] - boid_df["centroid_x"].iloc[0]
boid_cy = boid_df["centroid_y"] - boid_df["centroid_y"].iloc[0]

# Smooth direction and dispersion
def smooth_safe(arr, window=31, poly=3):
    arr = np.array(arr)
    mask = ~np.isnan(arr)
    if np.sum(mask) > window:
        arr[mask] = savgol_filter(arr[mask], window, poly)
    return arr

aerial_disp = smooth_safe(aerial_df["dispersion"])
boid_disp = smooth_safe(boid_df["dispersion"])
aerial_dir = smooth_safe(aerial_df["direction_deg"])
boid_dir = smooth_safe(boid_df["direction_deg"])

# Correlation function with NaN masking
def compute_correlation(x, y):
    mask = ~np.isnan(x) & ~np.isnan(y)
    if np.sum(mask) > 2:
        return round(pearsonr(x[mask], y[mask])[0], 2)
    return np.nan

# Compute metrics
correlations = {
    "Dispersion": compute_correlation(boid_disp, aerial_disp),
    "Direction": compute_correlation(boid_dir, aerial_dir),
    "Centroid X": compute_correlation(boid_cx, aerial_cx),
    "Centroid Y": compute_correlation(boid_cy, aerial_cy),
}

# Display
print("| Metric         | Correlation Coefficient |")
print("| -------------- | ------------------------ |")
for k, v in correlations.items():
    mark = (
        "✅" if abs(v) > 0.7 else
        "⚠️" if abs(v) > 0.3 else
        "❌"
    )
    print(f"| **{k}** | {v: .2f} {mark} |")

from google.colab import files
import matplotlib as mpl
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from moviepy.editor import VideoFileClip, clips_array
from IPython.display import HTML
from matplotlib.animation import FFMpegWriter
from matplotlib.animation import FFMpegWriter
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import matplotlib.patches as patches

mpl.rcParams['xtick.labelsize']  = 22   # x‑tick labels
mpl.rcParams['ytick.labelsize']  = 22   # y‑tick labels

# Use known video path or change if needed
video_path = "/content/cow aerial 2 low.mov"
clip = VideoFileClip(video_path)
VIDEO_DURATION = clip.duration
FPS = int(clip.fps)
TIMESTEPS = int(VIDEO_DURATION * FPS)
video_size = clip.size

NUM_COWS = 120
FIELD_SIZE = 200
MIN_SPEED = 0.2
MAX_SPEED = 1.0
VISUAL_RANGE = 12
PROTECTED_RANGE = 3

def generate_directional_initial_positions(num_cows, field_size):
    np.random.seed(42)
    x = np.random.normal(loc=70, scale=25, size=num_cows)
    y = np.random.normal(loc=100, scale=30, size=num_cows)
    x = np.clip(x, 0, field_size)
    y = np.clip(y, 0, field_size)
    return np.stack([x, y], axis=1)

def simulate_cloud_herd_behavior_v9(
    num_cows=120,
    field_size=200,
    timesteps=2040,
    fps=60,
    turn_start_sec=7,
    pause_probability=0.05,
    visual_range=16,
    protected_range=4
):
    import numpy as np

    np.random.seed(42)
    positions = generate_directional_initial_positions(num_cows, field_size)
    initial_angle = np.radians(12)
    velocities = np.array([
        [np.cos(initial_angle), np.sin(initial_angle)]
        for _ in range(num_cows)
    ]) * 0.3

    herd_drift = np.mean(velocities, axis=0)
    turn_start_frame = int(fps * turn_start_sec)
    final_goal = np.array([20.0, 20.0])

    wander_angles = np.random.uniform(-10, 10, size=num_cows)
    fan_out_bias = np.random.uniform(0.8, 1.2, size=num_cows)
    paused = np.random.rand(num_cows) < pause_probability
    trajectory = []

    for t in range(timesteps):
        new_positions = positions.copy()
        new_velocities = velocities.copy()

        # Goal steering (start after 7s)
        if t > turn_start_frame:
            turn_duration = 800
            progress = min((t - turn_start_frame) / turn_duration, 1.0)
            target_vector = final_goal - np.mean(positions, axis=0)
            target_vector /= (np.linalg.norm(target_vector) + 1e-4)
            directional_turn = target_vector * 0.15 * progress
        else:
            directional_turn = np.zeros(2)

        # Fanning behavior
        fan_progress = max(0, (t - 1200) / (2040 - 1200))
        max_fan_angle = 25
        fan_turns = np.radians(fan_out_bias * max_fan_angle * fan_progress)

        for i in range(num_cows):
            pos_i = positions[i]
            vel_i = velocities[i]

            repel_force = np.zeros(2)
            align_force = np.zeros(2)
            align_count = 0

            for j in range(num_cows):
                if i == j:
                    continue
                offset = positions[j] - pos_i
                dist = np.linalg.norm(offset)

                if dist < protected_range:
                    repel_force -= 2.8 * offset / (dist + 1e-4)
                elif dist < visual_range:
                    align_force += velocities[j]
                    align_count += 1

            if align_count > 0:
                align_force /= align_count
                align_force = align_force / (np.linalg.norm(align_force) + 1e-4)
                align_force *= 0.05

            # Cow-specific wander bias
            wander_angle_rad = np.radians(wander_angles[i])
            wander_rotation = np.array([
                [np.cos(wander_angle_rad), -np.sin(wander_angle_rad)],
                [np.sin(wander_angle_rad),  np.cos(wander_angle_rad)]
            ])
            wander_bias = wander_rotation @ herd_drift * 0.05

            # Directional fan curve
            fan_rot = np.array([
                [np.cos(fan_turns[i]), -np.sin(fan_turns[i])],
                [np.sin(fan_turns[i]),  np.cos(fan_turns[i])]
            ])
            fanned_turn = fan_rot @ directional_turn

            # ---------------------------
            # UPDATED EXIT + DISPERSAL
            # ---------------------------
            exit_phase = max(0, (t - 1260) / (2040 - 1260))
            exit_drift_vector = np.array([-0.035, -0.055]) * exit_phase
            repel_force *= (1.0 - 0.7 * exit_phase)
            align_force *= (1.0 - 0.5 * exit_phase)
            spread_force = np.zeros(2)
            goal_damp = (1.0 - 1.0 * exit_phase)

            # Combine all forces
            raw_velocity = (
                repel_force * 0.15 +
                align_force +
                wander_bias +
                fanned_turn * goal_damp +
                spread_force +
                exit_drift_vector
            )

            # Smooth velocity (momentum-like behavior)
            new_vel = 0.85 * vel_i + 0.15 * raw_velocity

            # Speed control
            speed = np.linalg.norm(new_vel)
            if speed < MIN_SPEED:
                new_vel = (new_vel / (speed + 1e-8)) * MIN_SPEED
            elif speed > MAX_SPEED:
                new_vel = (new_vel / speed) * MAX_SPEED

            # Grazing pauses (fade over time)
            pause_decay = max(0.5, 1 - (t / timesteps))
            dynamic_pause_prob = pause_probability * pause_decay
            if paused[i]:
                new_vel *= 0.6
                if np.random.rand() < 0.002:
                    paused[i] = False
            else:
                if np.random.rand() < dynamic_pause_prob:
                    paused[i] = True

            # Update wander direction
            wander_angles[i] += np.random.normal(scale=0.4)
            wander_angles[i] = np.clip(wander_angles[i], -25, 25)

            new_positions[i] += new_vel
            new_velocities[i] = new_vel

        # Let cows exit freely after 28s
        if t < 1680:
            positions = np.clip(new_positions, 0, field_size)
        else:
            positions = new_positions

        velocities = new_velocities
        trajectory.append(positions.copy())

    return trajectory




def animate_trajectory(trajectory):
    # Match the real video pixel size
    target_w, target_h = video_size
    DPI = 200
    figsize = (target_w / DPI, target_h / DPI)

    # Pure white background
    plt.rcParams['savefig.transparent'] = False
    plt.rcParams['figure.facecolor'] = 'white'
    plt.rcParams['axes.facecolor'] = 'white'

    fig, ax = plt.subplots(figsize=figsize, dpi=DPI)

    # Small, crisp dots
    scat = ax.scatter([], [], c='#1f77b4', s=10, marker='o',
                      linewidths=0, edgecolors='none', antialiased=False)

    ax.set_xlim(0, FIELD_SIZE)
    ax.set_ylim(0, FIELD_SIZE)
    ax.set_aspect('equal')
    ax.axis('off')
    ax.set_position([0, 0, 1, 1])  # fill the figure
    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)

    # Add thin paddock border
    frame = patches.Rectangle((0, 0), FIELD_SIZE, FIELD_SIZE,
                              fill=False, linewidth=1.0, edgecolor=(0, 0, 0, 0.15))
    ax.add_patch(frame)

    def update(frame_i):
        scat.set_offsets(trajectory[frame_i])
        return scat,

    ani = animation.FuncAnimation(
        fig, update, frames=len(trajectory), interval=1000/FPS, blit=False
    )

    writer = FFMpegWriter(
        fps=FPS,
        codec='libx264',
        bitrate=12000,
        extra_args=['-pix_fmt', 'yuv420p', '-crf', '18', '-preset', 'slow']
    )
    ani.save("boid_simulation.mp4", writer=writer, dpi=DPI)
    plt.close()


def create_side_by_side():
    # Both clips already have identical size and fps now, so avoid extra resizes
    real_clip = VideoFileClip(video_path).set_fps(FPS)
    sim_clip  = VideoFileClip("boid_simulation.mp4").set_fps(FPS)

    # If your real video isn't the same size, resize THAT to the sim size to avoid
    # re-encoding the sim again (pick one direction only)
    if real_clip.size != sim_clip.size:
        real_clip = real_clip.resize(newsize=sim_clip.size)

    combined = clips_array([[real_clip, sim_clip]])
    # Write with higher bitrate to avoid side-by-side recompression blur
    combined.write_videofile(
        "side_by_side_comparison.mp4",
        fps=FPS,
        codec="libx264",
        bitrate="12000k",
        audio=False,
        preset="slow"
    )

trajectory = simulate_cloud_herd_behavior_v9()
animate_trajectory(trajectory)
create_side_by_side()
files.download("side_by_side_comparison.mp4")

from google.colab import files
import matplotlib as mpl
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from moviepy.editor import VideoFileClip, clips_array
from IPython.display import HTML
from matplotlib.animation import FFMpegWriter
from matplotlib.animation import FFMpegWriter
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import matplotlib.patches as patches

mpl.rcParams['xtick.labelsize']  = 22   # x‑tick labels
mpl.rcParams['ytick.labelsize']  = 22   # y‑tick labels

# Use known video path or change if needed
video_path = "/content/cow aerial 2 low.mov"
clip = VideoFileClip(video_path)
VIDEO_DURATION = clip.duration
FPS = int(clip.fps)
TIMESTEPS = int(VIDEO_DURATION * FPS)
video_size = clip.size

NUM_COWS = 120
FIELD_SIZE = 200
MIN_SPEED = 0.2
MAX_SPEED = 1.0
VISUAL_RANGE = 12
PROTECTED_RANGE = 3

def generate_directional_initial_positions(num_cows, field_size):
    np.random.seed(42)
    x = np.random.normal(loc=70, scale=25, size=num_cows)
    y = np.random.normal(loc=100, scale=30, size=num_cows)
    x = np.clip(x, 0, field_size)
    y = np.clip(y, 0, field_size)
    return np.stack([x, y], axis=1)

def simulate_cloud_herd_behavior_v9(
    num_cows=120,
    field_size=200,
    timesteps=2040,
    fps=60,
    turn_start_sec=7,
    pause_probability=0.05,
    visual_range=16,
    protected_range=4
):
    import numpy as np

    np.random.seed(42)
    positions = generate_directional_initial_positions(num_cows, field_size)
    initial_angle = np.radians(12)
    velocities = np.array([
        [np.cos(initial_angle), np.sin(initial_angle)]
        for _ in range(num_cows)
    ]) * 0.3

    herd_drift = np.mean(velocities, axis=0)
    turn_start_frame = int(fps * turn_start_sec)
    final_goal = np.array([20.0, 20.0])

    wander_angles = np.random.uniform(-10, 10, size=num_cows)
    fan_out_bias = np.random.uniform(0.8, 1.2, size=num_cows)
    paused = np.random.rand(num_cows) < pause_probability
    trajectory = []

    for t in range(timesteps):
        new_positions = positions.copy()
        new_velocities = velocities.copy()

        # Goal steering (start after 7s)
        if t > turn_start_frame:
            turn_duration = 800
            progress = min((t - turn_start_frame) / turn_duration, 1.0)
            target_vector = final_goal - np.mean(positions, axis=0)
            target_vector /= (np.linalg.norm(target_vector) + 1e-4)
            directional_turn = target_vector * 0.15 * progress
        else:
            directional_turn = np.zeros(2)

        # Fanning behavior
        fan_progress = max(0, (t - 1200) / (2040 - 1200))
        max_fan_angle = 25
        fan_turns = np.radians(fan_out_bias * max_fan_angle * fan_progress)

        for i in range(num_cows):
            pos_i = positions[i]
            vel_i = velocities[i]

            repel_force = np.zeros(2)
            align_force = np.zeros(2)
            align_count = 0

            for j in range(num_cows):
                if i == j:
                    continue
                offset = positions[j] - pos_i
                dist = np.linalg.norm(offset)

                if dist < protected_range:
                    repel_force -= 2.8 * offset / (dist + 1e-4)
                elif dist < visual_range:
                    align_force += velocities[j]
                    align_count += 1

            if align_count > 0:
                align_force /= align_count
                align_force = align_force / (np.linalg.norm(align_force) + 1e-4)
                align_force *= 0.05

            # Cow-specific wander bias
            wander_angle_rad = np.radians(wander_angles[i])
            wander_rotation = np.array([
                [np.cos(wander_angle_rad), -np.sin(wander_angle_rad)],
                [np.sin(wander_angle_rad),  np.cos(wander_angle_rad)]
            ])
            wander_bias = wander_rotation @ herd_drift * 0.05

            # Directional fan curve
            fan_rot = np.array([
                [np.cos(fan_turns[i]), -np.sin(fan_turns[i])],
                [np.sin(fan_turns[i]),  np.cos(fan_turns[i])]
            ])
            fanned_turn = fan_rot @ directional_turn

            # ---------------------------
            # UPDATED EXIT + DISPERSAL
            # ---------------------------
            exit_phase = max(0, (t - 1260) / (2040 - 1260))
            exit_drift_vector = np.array([-0.035, -0.055]) * exit_phase
            repel_force *= (1.0 - 0.7 * exit_phase)
            align_force *= (1.0 - 0.5 * exit_phase)
            spread_force = np.zeros(2)
            goal_damp = (1.0 - 1.0 * exit_phase)

            # Combine all forces
            raw_velocity = (
                repel_force * 0.15 +
                align_force +
                wander_bias +
                fanned_turn * goal_damp +
                spread_force +
                exit_drift_vector
            )

            # Smooth velocity (momentum-like behavior)
            new_vel = 0.85 * vel_i + 0.15 * raw_velocity

            # Speed control
            speed = np.linalg.norm(new_vel)
            if speed < MIN_SPEED:
                new_vel = (new_vel / (speed + 1e-8)) * MIN_SPEED
            elif speed > MAX_SPEED:
                new_vel = (new_vel / speed) * MAX_SPEED

            # Grazing pauses (fade over time)
            pause_decay = max(0.5, 1 - (t / timesteps))
            dynamic_pause_prob = pause_probability * pause_decay
            if paused[i]:
                new_vel *= 0.6
                if np.random.rand() < 0.002:
                    paused[i] = False
            else:
                if np.random.rand() < dynamic_pause_prob:
                    paused[i] = True

            # Update wander direction
            wander_angles[i] += np.random.normal(scale=0.4)
            wander_angles[i] = np.clip(wander_angles[i], -25, 25)

            new_positions[i] += new_vel
            new_velocities[i] = new_vel

        # Let cows exit freely after 28s
        if t < 1680:
            positions = np.clip(new_positions, 0, field_size)
        else:
            positions = new_positions

        velocities = new_velocities
        trajectory.append(positions.copy())

    return trajectory

def animate_trajectory(trajectory):
    # Match drone clip height exactly, adjust width to match paddock shape
    target_h = video_size[1]
    target_w = video_size[0]

    DPI = 200
    paddock_aspect = FIELD_SIZE / FIELD_SIZE  # change if rectangular paddock
    figsize = (target_w / DPI, target_h / DPI)

    plt.rcParams['savefig.transparent'] = False
    plt.rcParams['figure.facecolor'] = 'white'
    plt.rcParams['axes.facecolor'] = 'white'

    fig, ax = plt.subplots(figsize=figsize, dpi=DPI)

    scat = ax.scatter([], [], c='#1f77b4', s=10, marker='o',
                      linewidths=0, edgecolors='none', antialiased=False)

    ax.set_xlim(0, FIELD_SIZE)
    ax.set_ylim(0, FIELD_SIZE)
    ax.set_aspect('equal')
    ax.axis('off')

    # Ensure no padding or margins are added around the plot area
    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)
    ax.set_position([0, 0, 1, 1])

    # Light paddock outline
    frame = patches.Rectangle((0, 0), FIELD_SIZE, FIELD_SIZE,
                              fill=False, linewidth=1.0, edgecolor=(0, 0, 0, 0.15))
    ax.add_patch(frame)

    def update(frame_i):
        scat.set_offsets(trajectory[frame_i])
        return scat,

    ani = animation.FuncAnimation(fig, update, frames=len(trajectory),
                                  interval=1000/FPS, blit=False)

    writer = FFMpegWriter(
        fps=FPS, codec='libx264', bitrate=12000,
        extra_args=['-pix_fmt', 'yuv420p', '-crf', '18', '-preset', 'slow']
    )
    ani.save("boid_simulation.mp4", writer=writer, dpi=DPI)
    plt.close()



def create_side_by_side():
    sim_clip = VideoFileClip("boid_simulation.mp4").set_fps(FPS)
    real_clip = VideoFileClip(video_path).set_fps(FPS)

    real_clip = real_clip.resize(newsize=sim_clip.size)  # match sim width exactly

    combined = clips_array([[real_clip, sim_clip]])
    combined.write_videofile(
        "side_by_side_comparison.mp4",
        fps=FPS, codec="libx264", bitrate="12000k", audio=False, preset="slow"
    )


trajectory = simulate_cloud_herd_behavior_v9()
animate_trajectory(trajectory)
create_side_by_side()
files.download("side_by_side_comparison.mp4")

from moviepy.editor import VideoFileClip, clips_array

# === INPUT FILE PATHS ===
video1_path = "/content/cow aerial 2 low.mov"
video2_path = "/content/boid_simulation_cropped.mp4"

# Load videos
clip1 = VideoFileClip(video1_path)
clip2 = VideoFileClip(video2_path)

# === Align by height without scaling ===
if clip1.h != clip2.h:
    max_height = max(clip1.h, clip2.h)
    # Pad the shorter one with black bars so heights match
    clip1 = clip1.margin(
        top=(max_height - clip1.h) // 2,
        bottom=(max_height - clip1.h + 1) // 2,
        color=(0, 0, 0)
    )
    clip2 = clip2.margin(
        top=(max_height - clip2.h) // 2,
        bottom=(max_height - clip2.h + 1) // 2,
        color=(0, 0, 0)
    )

# === Combine side-by-side ===
final_clip = clips_array([[clip1, clip2]])

# === Export video ===
final_clip.write_videofile(
    "side_by_side.mp4",
    codec="libx264",
    audio=False,         # No audio to speed up
    preset="ultrafast",  # Fast encoding
    bitrate="5000k"      # Higher bitrate for quality
)

print("✅ Done! Saved as side_by_side.mp4")

#simulation 3 with section 1 equations
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import matplotlib.patches as patches
from matplotlib.patches import Patch

# --- Constants ---
NUM_COWS = 60
FIELD_SIZE = 80
DT = 0.2
STEPS = 500

# --- Behavior States ---
STATE_GRAZING = 0
STATE_WALKING = 1
STATE_REACTING = 2

# --- Parameters ---
MAX_SPEED = 0.7
TURN_LIMIT = 0.2
VISUAL_RANGE = 14
DESIRED_SPACING = 4.0
FENCE_TRIGGER = 12
FENCE_REACT_TIME = 15

# --- Bio-Informed Parameters ---
f = 8000  # Hz
A = 80    # dB
sigma_f = 1000
A50 = 70
s = 0.3
gamma = 0.1
t50 = 25
lambda_ = 0.05
k1 = 1.0
k2 = 10.0
theta = 0.5
N_val = 1.0

# --- Initialization ---
np.random.seed(42)
positions = np.random.rand(NUM_COWS, 2) * 50 + 10
angles = np.random.rand(NUM_COWS) * 2 * np.pi
velocities = np.stack((np.cos(angles), np.sin(angles)), axis=1) * 0.5
states = np.full(NUM_COWS, STATE_GRAZING)
state_timers = np.random.randint(20, 60, size=NUM_COWS)
cooldown_timer = np.zeros(NUM_COWS, dtype=int)
arousal = np.zeros(NUM_COWS)
fence_timers = np.zeros(NUM_COWS)
in_recovery = np.zeros(NUM_COWS, dtype=bool)
cooldown_timer = np.zeros(NUM_COWS, dtype=int)

# --- Traits ---
fopt = np.random.normal(8000, 100, NUM_COWS)
reaction_threshold = np.random.uniform(0.7, 1.2, NUM_COWS)
wander_bias = np.random.uniform(0.05, 0.25, NUM_COWS)
social_strength = np.random.uniform(0.3, 1.0, NUM_COWS)
group_influence = np.random.uniform(0.8, 1.3, NUM_COWS)

# --- Social Bonds ---
SOCIAL_PAIRS = [(i, i+1) for i in range(0, NUM_COWS-1, 2)]
social_matrix = np.zeros((NUM_COWS, NUM_COWS))
for i, j in SOCIAL_PAIRS:
    social_matrix[i, j] = social_matrix[j, i] = 1

# --- Grazing Patches ---
grazing_patches = [(20, 20, 15, 10), (40, 50, 20, 15), (60, 15, 10, 10)]

# --- Buffers ---
trajectory = []
state_colors = []
cow_labels = []
behavior_counts = []

# --- Main Simulation Loop ---
for step in range(STEPS):
    frame_colors = []
    labels = []
    accelerations = np.zeros_like(velocities)
    grazing_count, walking_count, reacting_count = 0, 0, 0

    for i in range(NUM_COWS):
        pos_i = positions[i]
        vel_i = velocities[i]
        state = states[i]

        # --- Herd Forces ---
        sep, coh, align, bond = np.zeros(2), np.zeros(2), np.zeros(2), np.zeros(2)
        count, bond_count = 0, 0

        for j in range(NUM_COWS):
            if i == j:
                continue
            offset = positions[j] - pos_i
            dist = np.linalg.norm(offset)
            if dist < VISUAL_RANGE and dist > 1e-4:
                direction = offset / dist
                if dist < DESIRED_SPACING:
                    sep += ((DESIRED_SPACING - dist)**2) * (-direction)
                elif dist < DESIRED_SPACING * 2:
                    sep += 0.1 * (1 - dist / (DESIRED_SPACING * 2)) * (-direction)
                coh += (offset * np.clip((dist - DESIRED_SPACING) / VISUAL_RANGE, 0, 1))
                align += velocities[j]
                count += 1
                if social_matrix[i, j]:
                    bond += offset
                    bond_count += 1

        if count > 0:
            coh = coh / count - vel_i
            align = align / count - vel_i
        if bond_count > 0:
            bond = bond / bond_count - vel_i * social_strength[i]

        # --- Fence Avoidance ---
        avoid = np.zeros(2)
        in_fence_zone = False
        if pos_i[0] < FENCE_TRIGGER:
            avoid += np.array([1.0, 0.0])
            in_fence_zone = True
        elif pos_i[0] > FIELD_SIZE - FENCE_TRIGGER:
            avoid += np.array([-1.0, 0.0])
            in_fence_zone = True
        if pos_i[1] < FENCE_TRIGGER:
            avoid += np.array([0.0, 1.0])
            in_fence_zone = True
        elif pos_i[1] > FIELD_SIZE - FENCE_TRIGGER:
            avoid += np.array([0.0, -1.0])
            in_fence_zone = True
        fence_timers[i] = fence_timers[i] + 1 if in_fence_zone else 0

        # --- Arousal ---
        for j in range(NUM_COWS):
            if j != i and np.linalg.norm(positions[j] - pos_i) < 10.0:
                arousal[i] += 0.05 * arousal[j]
        arousal[i] = np.clip(arousal[i] * 0.95, 0, 1.5)

        # --- Grazing Attraction ---
        patch_pull = np.zeros(2)
        if state == STATE_GRAZING:
            for gx, gy, w, h in grazing_patches:
                center = np.array([gx + w/2, gy + h/2])
                dist = np.linalg.norm(center - pos_i)
                if dist < 30:
                    patch_pull += 0.2 * (center - pos_i) / (dist + 1e-4)

        # --- Drift & Wander ---
        edge_bias = np.zeros(2)
        if step % 200 < 50 and i % 10 == 0:
            edge_bias = np.random.uniform(-1, 1, size=2)
            edge_bias /= np.linalg.norm(edge_bias) + 1e-4
            edge_bias *= 0.4
        wander = wander_bias[i] * np.random.uniform(-1, 1, size=2) + edge_bias
        drift = np.array([np.sin(0.01 * step), np.cos(0.01 * step)]) * 0.1

        # --- Bio-Informed Reactivity ---
        F_f = np.exp(-((f - fopt[i])**2) / (2 * sigma_f**2))
        S_A = 1 / (1 + np.exp(-s * (A - A50)))
        L_t = 1 / (1 + np.exp(-gamma * (step - t50)))
        H_t = np.exp(-lambda_ * step)
        M_t = k1 * F_f * S_A * H_t * N_val
        P_turn = 1 / (1 + np.exp(-group_influence[i] * k2 * (S_A * F_f * L_t - theta)))

        # --- Acceleration by State ---
        if state == STATE_GRAZING:
            acc = 0.6 * sep + 0.3 * patch_pull + 0.1 * drift
            color = 'green'
            grazing_count += 1
        elif state == STATE_WALKING:
            acc = 0.6 * sep + 0.2 * coh + 0.2 * drift + 0.1 * bond
            color = 'blue'
            walking_count += 1
        elif state == STATE_REACTING:
            acc = 1.0 * sep + 0.6 * avoid + 0.2 * bond
            color = 'red'
            reacting_count += 1

        acc += M_t * wander
        frame_colors.append(color)
        labels.append(str(i))

        # --- Velocity Update ---
        desired_heading = vel_i + acc * DT
        if np.linalg.norm(desired_heading) > 1e-4:
            desired_heading /= np.linalg.norm(desired_heading)
        angle_diff = np.arctan2(desired_heading[1], desired_heading[0]) - np.arctan2(vel_i[1], vel_i[0])
        angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi
        angle_diff = np.clip(angle_diff, -TURN_LIMIT, TURN_LIMIT)
        new_angle = np.arctan2(vel_i[1], vel_i[0]) + angle_diff
        speed_factor = 0.4 if state == STATE_GRAZING else 1.0
        velocities[i] = np.array([np.cos(new_angle), np.sin(new_angle)]) * MAX_SPEED * speed_factor
        positions[i] += velocities[i] * DT
        positions[i] = np.clip(positions[i], 0, FIELD_SIZE)

        # --- State Transitions ---
        state_timers[i] -= 1

        if states[i] == STATE_REACTING:
            if state_timers[i] <= 0:
                # Exit reacting state into cooldown
                in_recovery[i] = True
                cooldown_timer[i] = np.random.randint(20, 40)
                states[i] = np.random.choice([STATE_GRAZING, STATE_WALKING])
                state_timers[i] = np.random.randint(30, 80)

        elif in_recovery[i]:
            cooldown_timer[i] -= 1
            if cooldown_timer[i] <= 0:
                in_recovery[i] = False  # Recovery done, normal behavior resumes

        elif fence_timers[i] > FENCE_REACT_TIME or arousal[i] > reaction_threshold[i]:
            states[i] = STATE_REACTING
            state_timers[i] = 10

        elif state_timers[i] <= 0:
            states[i] = np.random.choice([STATE_GRAZING, STATE_WALKING])
            state_timers[i] = np.random.randint(30, 80)



    trajectory.append(positions.copy())
    state_colors.append(frame_colors)
    cow_labels.append(labels)
    behavior_counts.append((grazing_count, walking_count, reacting_count))

# --- Visualization ---
fig, ax = plt.subplots()
scat = ax.scatter([], [], s=25)
texts = [ax.text(0, 0, "", fontsize=6) for _ in range(NUM_COWS)]
count_text = ax.text(FIELD_SIZE / 2, FIELD_SIZE + 6, "", fontsize=10, color='black', ha='center',
                     bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))

for gx, gy, w, h in grazing_patches:
    ax.add_patch(patches.Rectangle((gx, gy), w, h, color='lightgreen', alpha=0.3))
fence_color = (1, 0, 0, 0.1)
ax.add_patch(plt.Rectangle((0, 0), FENCE_TRIGGER, FIELD_SIZE, color=fence_color))
ax.add_patch(plt.Rectangle((FIELD_SIZE - FENCE_TRIGGER, 0), FENCE_TRIGGER, FIELD_SIZE, color=fence_color))
ax.add_patch(plt.Rectangle((0, 0), FIELD_SIZE, FENCE_TRIGGER, color=fence_color))
ax.add_patch(plt.Rectangle((0, FIELD_SIZE - FENCE_TRIGGER), FIELD_SIZE, FENCE_TRIGGER, color=fence_color))

legend_patches = [
    Patch(color='green', label='Grazing'),
    Patch(color='blue', label='Walking'),
    Patch(color='red', label='Reacting'),
]
ax.legend(handles=legend_patches, loc='lower left')
ax.set_xlim(0, FIELD_SIZE)
ax.set_ylim(0, FIELD_SIZE + 10)
ax.set_aspect('equal')

ax.set_xticks([])
ax.set_yticks([])
ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)

def update(frame):
    scat.set_offsets(trajectory[frame])
    scat.set_color(state_colors[frame])
    for i, text in enumerate(texts):
        text.set_position(trajectory[frame][i])
        text.set_text(cow_labels[frame][i])
    grazing, walking, reacting = behavior_counts[frame]
    count_text.set_text(f"Grazing: {grazing} | Walking: {walking} | Reacting: {reacting}")
    return scat, *texts, count_text

ani = animation.FuncAnimation(fig, update, frames=STEPS, interval=40)
ani.save("simulation 3 with section 1 equations.mp4", writer="ffmpeg", fps=25)
plt.show()

# simulation 3 with section 1 equations + audio→shock escalation + shock event log
# + VIDEO OVERLAYS: yellow ring = audio cue window, magenta "x" = electric shock
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import matplotlib.patches as patches
from matplotlib.patches import Patch
from matplotlib.lines import Line2D

# --- Constants ---
NUM_COWS   = 60
FIELD_SIZE = 80
DT         = 0.2
STEPS      = 500  # interpret as "1 day" for rate metrics

# --- Behavior States ---
STATE_GRAZING  = 0
STATE_WALKING  = 1
STATE_REACTING = 2

# --- Parameters ---
MAX_SPEED        = 0.7
TURN_LIMIT       = 0.2
VISUAL_RANGE     = 14
DESIRED_SPACING  = 4.0
FENCE_TRIGGER    = 16
FENCE_REACT_TIME = 15

# --- Bio-Informed Parameters (Section 1) ---
f       = 8000  # Hz
A       = 80    # dB
sigma_f = 1000
A50     = 70
s       = 0.3
gamma   = 0.1
t50     = 25
lambda_ = 0.05
k1      = 1.0
k2      = 10.0
theta   = 0.5
N_val   = 1.0

# --- Learning / Shock Policy ---
TRAIN_FRACTION = 0.30
TRAIN_STEPS    = int(STEPS * TRAIN_FRACTION)

# Targets (per cow per "day" = 500 steps)
TARGET_TRAIN_LOW, TARGET_TRAIN_HIGH = 1.0, 6.5
TARGET_POST_LOW,  TARGET_POST_HIGH  = 0.06, 0.12

# Post-learning: fraction of cues that escalate (bounds)
POST_ESCALATE_FRAC_MIN, POST_ESCALATE_FRAC_MAX = 0.20, 0.30  # NEW: min bumped from 0.10→0.12

# Shock logistics
CUE_GRACE_STEPS    = 4
SHOCK_REFRACTORY   = 10
MAX_SHOCKS_PER_CUE = 1
SHOCK_MARKER_DUR   = 12

# --- Post-phase outward exploration (new) ---
POST_OUTWARD_BIAS = 0.16    # mild drift toward nearest edge after training
EDGE_PROBE_PERIOD = 60      # frames between probe windows
EDGE_PROBE_DUR    = 14      # frames per probe window
EDGE_PROBE_PUSH   = 0.32    # strength of probe push toward edge
EDGE_PROBE_GROUPS = 6       # rotate subgroups so not all probe at once


# Adaptive controller gains
GAIN_UNDER = 1.10
GAIN_OVER  = 0.92
ESC_INIT_TRAIN = 0.85
ESC_INIT_POST  = 0.22  # NEW: start a bit higher to avoid 0 post shocks when cues are few

# --- NEW: Post-phase outward-bias / edge-probe to create a few post cues ---
POST_OUTWARD_BIAS  = 0.18   # gentle outward drift after training
EDGE_PROBE_PERIOD  = 50     # every N steps
EDGE_PROBE_DUR     = 16     # for this many steps
EDGE_PROBE_PUSH    = 0.35   # stronger outward nudge during probe burst
EDGE_PROBE_GROUPS  = 6      # split herd so probes rotate (not everyone at once)

# --- Training-phase outward exploration (new) ---
TRAIN_OUTWARD_BIAS = 0.22
TRAIN_PROBE_PERIOD = 45
TRAIN_PROBE_DUR    = 14
TRAIN_PROBE_PUSH   = 0.40
TRAIN_PROBE_GROUPS = 6


# --- Initialization ---
np.random.seed(42)
positions      = np.random.rand(NUM_COWS, 2) * 50 + 10
angles         = np.random.rand(NUM_COWS) * 2 * np.pi
velocities     = np.stack((np.cos(angles), np.sin(angles)), axis=1) * 0.5
states         = np.full(NUM_COWS, STATE_GRAZING)
state_timers   = np.random.randint(20, 60, size=NUM_COWS)
cooldown_timer = np.zeros(NUM_COWS, dtype=int)
arousal        = np.zeros(NUM_COWS)
fence_timers   = np.zeros(NUM_COWS)
in_recovery    = np.zeros(NUM_COWS, dtype=bool)

# Traits
fopt               = np.random.normal(8000, 100, NUM_COWS)
reaction_threshold = np.random.uniform(0.7, 1.2, NUM_COWS)
wander_bias        = np.random.uniform(0.05, 0.25, NUM_COWS)
social_strength    = np.random.uniform(0.3, 1.0, NUM_COWS)
group_influence    = np.random.uniform(0.8, 1.3, NUM_COWS)

# Social bonds
SOCIAL_PAIRS = [(i, i+1) for i in range(0, NUM_COWS-1, 2)]
social_matrix = np.zeros((NUM_COWS, NUM_COWS))
for i, j in SOCIAL_PAIRS:
    social_matrix[i, j] = social_matrix[j, i] = 1

# Grazing patches
grazing_patches = [(20, 20, 15, 10), (40, 50, 20, 15), (60, 15, 10, 10)]

# --- Audio Cue / Shock Tracking ---
pending_cue_until = np.zeros(NUM_COWS, dtype=int)
cue_open          = np.zeros(NUM_COWS, dtype=bool)
refractory        = np.zeros(NUM_COWS, dtype=int)

# --- Cue / Shock Logging ---
shock_log   = []
cue_counter = 0
last_cue_id = np.full(NUM_COWS, -1)

# --- Metrics ---
total_cues = total_shocks = 0
train_cues = post_cues = 0
train_shocks = post_shocks = 0
train_escalations = post_escalations = 0

# Adaptive escalation probabilities
p_escalate_train = ESC_INIT_TRAIN
p_escalate_post  = ESC_INIT_POST

# --- Buffers for visualization ---
trajectory = []
state_colors = []
cow_labels = []
behavior_counts = []

cue_marker_positions_per_frame   = []
shock_marker_positions_per_frame = []
shock_flash_schedule = []

# Helper to push away from nearest edge (used for direction checks)
def away_from_nearest_edge(pos, field=FIELD_SIZE):
    d = np.array([pos[0], field-pos[0], pos[1], field-pos[1]])  # left, right, bottom, top distances
    edge = np.argmin(d)
    if edge == 0:   return np.array([ 1.0,  0.0])
    if edge == 1:   return np.array([-1.0,  0.0])
    if edge == 2:   return np.array([ 0.0,  1.0])
    return np.array([ 0.0, -1.0])

center = np.array([FIELD_SIZE/2, FIELD_SIZE/2])  # NEW: reuse for outward bias

# --- Main Simulation Loop ---
for step in range(STEPS):
    frame_colors = []
    labels = []
    accelerations = np.zeros_like(velocities)
    grazing_count, walking_count, reacting_count = 0, 0, 0

    in_training_phase = (step < TRAIN_STEPS)

    # ---- Phase targets for controller ----
    steps_elapsed = max(step, 1)  # avoid div-by-zero
    days_elapsed  = steps_elapsed / STEPS
    obs_shocks_per_cow_day = (total_shocks / max(NUM_COWS, 1)) / max(days_elapsed, 1e-6)

    if in_training_phase:
        if obs_shocks_per_cow_day < TARGET_TRAIN_LOW:
            p_escalate_train *= GAIN_UNDER
        elif obs_shocks_per_cow_day > TARGET_TRAIN_HIGH:
            p_escalate_train *= GAIN_OVER
        p_escalate_train = float(np.clip(p_escalate_train, 0.02, 0.95))
    else:
        if obs_shocks_per_cow_day < TARGET_POST_LOW:
            p_escalate_post *= GAIN_UNDER
        elif obs_shocks_per_cow_day > TARGET_POST_HIGH:
            p_escalate_post *= GAIN_OVER
        # keep within literature band
        p_escalate_post = float(np.clip(p_escalate_post, POST_ESCALATE_FRAC_MIN, POST_ESCALATE_FRAC_MAX))

    for i in range(NUM_COWS):
        pos_i = positions[i]
        vel_i = velocities[i]
        state = states[i]

        # Refractory decrement
        if refractory[i] > 0:
            refractory[i] -= 1

        # --- Herd Forces ---
        sep = np.zeros(2); coh = np.zeros(2); align = np.zeros(2); bond = np.zeros(2)
        count = 0; bond_count = 0

        for j in range(NUM_COWS):
            if i == j:
                continue
            offset = positions[j] - pos_i
            dist = np.linalg.norm(offset)
            if dist < VISUAL_RANGE and dist > 1e-4:
                direction = offset / dist
                if dist < DESIRED_SPACING:
                    sep += ((DESIRED_SPACING - dist)**2) * (-direction)
                elif dist < DESIRED_SPACING * 2:
                    sep += 0.1 * (1 - dist / (DESIRED_SPACING * 2)) * (-direction)
                coh += (offset * np.clip((dist - DESIRED_SPACING) / VISUAL_RANGE, 0, 1))
                align += velocities[j]
                count += 1
                if social_matrix[i, j]:
                    bond += offset
                    bond_count += 1

        if count > 0:
            coh = coh / count - vel_i
            align = align / count - vel_i
        if bond_count > 0:
            bond = bond / bond_count - vel_i * social_strength[i]

        # --- Fence Avoidance ---
        avoid = np.zeros(2)
        in_fence_zone = False
        if pos_i[0] < FENCE_TRIGGER:
            avoid += np.array([1.0, 0.0]); in_fence_zone = True
        elif pos_i[0] > FIELD_SIZE - FENCE_TRIGGER:
            avoid += np.array([-1.0, 0.0]); in_fence_zone = True
        if pos_i[1] < FENCE_TRIGGER:
            avoid += np.array([0.0, 1.0]); in_fence_zone = True
        elif pos_i[1] > FIELD_SIZE - FENCE_TRIGGER:
            avoid += np.array([0.0, -1.0]); in_fence_zone = True

        fence_timers[i] = fence_timers[i] + 1 if in_fence_zone else 0

        # --- AUDIO CUE TRIGGER ---
        if fence_timers[i] == 1:
            cue_open[i] = True
            pending_cue_until[i] = step + CUE_GRACE_STEPS
            total_cues += 1
            cue_counter += 1
            last_cue_id[i] = cue_counter
            if in_training_phase:
                train_cues += 1
            else:
                post_cues += 1

        # --- Arousal (social contagion) ---
        for j in range(NUM_COWS):
            if j != i and np.linalg.norm(positions[j] - pos_i) < 10.0:
                arousal[i] += 0.05 * arousal[j]
        arousal[i] = np.clip(arousal[i] * 0.95, 0, 1.5)

        # --- Grazing Attraction ---
        patch_pull = np.zeros(2)
        if state == STATE_GRAZING:
            for gx, gy, w, h in grazing_patches:
                center = np.array([gx + w/2, gy + h/2])
                dist = np.linalg.norm(center - pos_i)
                if dist < 30:
                    patch_pull += 0.2 * (center - pos_i) / (dist + 1e-4)

        # --- Drift & Wander ---
        edge_bias = np.zeros(2)
        if step % 200 < 50 and i % 10 == 0:
            edge_bias = np.random.uniform(-1, 1, size=2)
            edge_bias /= np.linalg.norm(edge_bias) + 1e-4
            edge_bias *= 0.4

        wander = wander_bias[i] * np.random.uniform(-1, 1, size=2) + edge_bias
        drift = np.array([np.sin(0.01 * step), np.cos(0.01 * step)]) * 0.1

        if in_training_phase:
            # gentle outward drift to generate early cues
            to_edge = -away_from_nearest_edge(pos_i)
            drift  += TRAIN_OUTWARD_BIAS * to_edge

            # rotating probe bursts so not everyone probes at once
            grp = (step // TRAIN_PROBE_PERIOD) % TRAIN_PROBE_GROUPS
            if (step % TRAIN_PROBE_PERIOD) < TRAIN_PROBE_DUR and (i % TRAIN_PROBE_GROUPS) == grp:
                drift += TRAIN_PROBE_PUSH * to_edge

        # --- NEW: post-learning outward bias & rotating edge probes ---
        if not in_training_phase:
            # mild continuous nudge toward the nearest boundary (to create cues)
            to_edge = -away_from_nearest_edge(pos_i)      # (toward) edge direction
            drift  += POST_OUTWARD_BIAS * to_edge

            # rotating probe groups to avoid all-at-once swarms
            grp = (step // EDGE_PROBE_PERIOD) % EDGE_PROBE_GROUPS
            if (step % EDGE_PROBE_PERIOD) < EDGE_PROBE_DUR and (i % EDGE_PROBE_GROUPS) == grp:
                drift += EDGE_PROBE_PUSH * to_edge

        # --- NEW: post-phase gentle outward bias + rotating edge-probe bursts ---
        if not in_training_phase:
            # gentle outward drift for everyone
            outward = pos_i - center
            norm = np.linalg.norm(outward) + 1e-8
            outward /= norm
            drift += POST_OUTWARD_BIAS * outward

            # rotating groups get short, stronger "probe" pushes
            if (step % EDGE_PROBE_PERIOD) < EDGE_PROBE_DUR:
                group_id = (step // EDGE_PROBE_DUR) % EDGE_PROBE_GROUPS
                if (i % EDGE_PROBE_GROUPS) == group_id:
                    drift += EDGE_PROBE_PUSH * outward

        # --- Bio-Informed Reactivity ---
        F_f = np.exp(-((f - fopt[i])**2) / (2 * sigma_f**2))
        S_A = 1 / (1 + np.exp(-s * (A - A50)))
        L_t = 1 / (1 + np.exp(-gamma * (step - t50)))
        H_t = np.exp(-lambda_ * step)
        M_t = k1 * F_f * S_A * H_t * N_val
        P_turn = 1 / (1 + np.exp(-group_influence[i] * k2 * (S_A * F_f * L_t - theta)))

        # --- Acceleration by State ---
        if state == STATE_GRAZING:
            acc = 0.6 * sep + 0.3 * patch_pull + 0.1 * drift
            color = 'green'; grazing_count += 1
        elif state == STATE_WALKING:
            acc = 0.6 * sep + 0.2 * coh + 0.2 * drift + 0.1 * bond
            color = 'blue'; walking_count += 1
        elif state == STATE_REACTING:
            acc = 1.0 * sep + 0.6 * avoid + 0.2 * bond
            color = 'red'; reacting_count += 1

        acc += M_t * wander
        frame_colors.append(color)
        labels.append(str(i))

        # --- Velocity Update ---
        desired_heading = vel_i + acc * DT
        if np.linalg.norm(desired_heading) > 1e-4:
            desired_heading /= np.linalg.norm(desired_heading)
        angle_diff = np.arctan2(desired_heading[1], desired_heading[0]) - np.arctan2(vel_i[1], vel_i[0])
        angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi
        angle_diff = np.clip(angle_diff, -TURN_LIMIT, TURN_LIMIT)
        new_angle = np.arctan2(vel_i[1], vel_i[0]) + angle_diff
        speed_factor = 0.4 if state == STATE_GRAZING else 1.0
        velocities[i] = np.array([np.cos(new_angle), np.sin(new_angle)]) * MAX_SPEED * speed_factor
        positions[i] += velocities[i] * DT
        positions[i] = np.clip(positions[i], 0, FIELD_SIZE)

        # --- State Transitions ---
        state_timers[i] -= 1
        if states[i] == STATE_REACTING:
            if state_timers[i] <= 0:
                in_recovery[i] = True
                cooldown_timer[i] = np.random.randint(20, 40)
                states[i] = np.random.choice([STATE_GRAZING, STATE_WALKING])
                state_timers[i] = np.random.randint(30, 80)
        elif in_recovery[i]:
            cooldown_timer[i] -= 1
            if cooldown_timer[i] <= 0:
                in_recovery[i] = False
        elif fence_timers[i] > FENCE_REACT_TIME or arousal[i] > reaction_threshold[i]:
            states[i] = STATE_REACTING
            state_timers[i] = 10
        elif state_timers[i] <= 0:
            states[i] = np.random.choice([STATE_GRAZING, STATE_WALKING])
            state_timers[i] = np.random.randint(30, 80)

        # --- Cue Resolution: decide on escalation after grace window ---
        if cue_open[i] and step >= pending_cue_until[i]:
            # NEW: recompute warning-zone status on current position (was using stale flag)
            pos_now = positions[i].copy()
            still_in_warning = (
                (pos_now[0] < FENCE_TRIGGER) or
                (pos_now[0] > FIELD_SIZE - FENCE_TRIGGER) or
                (pos_now[1] < FENCE_TRIGGER) or
                (pos_now[1] > FIELD_SIZE - FENCE_TRIGGER)
            )
            if still_in_warning and refractory[i] == 0:
                # NEW: require movement toward the nearest edge to escalate
                to_edge_vec = -away_from_nearest_edge(pos_now)  # points toward edge
                moving_toward_edge = np.dot(velocities[i], to_edge_vec) >= -0.01
                if moving_toward_edge:
                    p = p_escalate_train if in_training_phase else p_escalate_post
                    if np.random.rand() < p:
                        # deliver exactly one shock for this cue
                        total_shocks += 1
                        refractory[i] = SHOCK_REFRACTORY
                        phase = "training" if in_training_phase else "post"
                        shock_log.append({
                            "step": step,
                            "time_s": step * DT,
                            "cow": i,
                            "phase": phase,
                            "cue_id": int(last_cue_id[i]),
                            "x": float(pos_now[0]),
                            "y": float(pos_now[1]),
                            "p_used": float(p)
                        })
                        # schedule a visible shock flash on video
                        shock_flash_schedule.append((step, step + SHOCK_MARKER_DUR, i))
                        if in_training_phase:
                            train_shocks += 1
                            train_escalations += 1
                        else:
                            post_shocks += 1
                            post_escalations += 1
            # close the cue window regardless (at most one shock per cue)
            cue_open[i] = False
            pending_cue_until[i] = 0

    # --- Build per-frame overlays ---
    cue_positions = []
    for i in range(NUM_COWS):
        if cue_open[i] and step < pending_cue_until[i]:
            cue_positions.append(positions[i].copy())
    cue_marker_positions_per_frame.append(np.array(cue_positions) if len(cue_positions) else np.empty((0,2)))

    shock_positions = []
    for (start_s, end_s, cow_id) in shock_flash_schedule:
        if start_s <= step < end_s:
            shock_positions.append(positions[cow_id].copy())
    shock_marker_positions_per_frame.append(np.array(shock_positions) if len(shock_positions) else np.empty((0,2)))

    trajectory.append(positions.copy())
    state_colors.append(frame_colors)
    cow_labels.append(labels)
    behavior_counts.append((grazing_count, walking_count, reacting_count))

# --- Metrics ---
def safe_div(a, b):
    return a / b if b > 0 else 0.0

days_train = max(TRAIN_STEPS / STEPS, 1e-9)
days_post  = max((STEPS - TRAIN_STEPS) / STEPS, 1e-9)

train_rate_per_cow_per_day = safe_div(train_shocks, NUM_COWS * days_train)
post_rate_per_cow_per_day  = safe_div(post_shocks,  NUM_COWS * days_post)
overall_rate_per_cow_per_day = safe_div(total_shocks, NUM_COWS * (STEPS / STEPS))

overall_escalation_rate = safe_div(total_shocks, total_cues) * 100.0
post_escalation_rate    = safe_div(post_shocks, post_cues) * 100.0
train_escalation_rate   = safe_div(train_shocks, train_cues) * 100.0

print("=== Audio → Shock Metrics ===")
print(f"Total cues: {total_cues}")
print(f"Total shocks: {total_shocks}  (training: {train_shocks}, post-learning: {post_shocks})")
print(f"Escalation rate (all cues): {overall_escalation_rate:.1f}%")
print(f"Escalation rate (training): {train_escalation_rate:.1f}%   | (post): {post_escalation_rate:.1f}%")
print(f"Training shocks/cow/day: {train_rate_per_cow_per_day:.2f}  target: {TARGET_TRAIN_LOW}–{TARGET_TRAIN_HIGH}")
print(f"Post-learning shocks/cow/day: {post_rate_per_cow_per_day:.3f}  target: {TARGET_POST_LOW}–{TARGET_POST_HIGH}")
print(f"Overall shocks/cow/day: {overall_rate_per_cow_per_day:.3f}")

print("\n=== Shock Event Log ===")
print(f"Shock events: {len(shock_log)}")
if len(shock_log) == 0:
    print("No shocks delivered.")
else:
    per_cow = np.zeros(NUM_COWS, dtype=int)
    for ev in shock_log:
        per_cow[ev["cow"]] += 1
    cows_with_shocks = np.count_nonzero(per_cow)
    print(f"Cows with ≥1 shock: {cows_with_shocks} / {NUM_COWS}")
    for ev in shock_log:
        print(
            f"[step {ev['step']:>3} @ {ev['time_s']:6.2f}s] "
            f"cow {ev['cow']:>2} | {ev['phase']:>8} | cue {ev['cue_id']:>3} | "
            f"pos=({ev['x']:.1f},{ev['y']:.1f}) | p={ev['p_used']:.3f}"
        )

# --- Visualization ---
fig, ax = plt.subplots(figsize=(8, 8), dpi=200)
scat = ax.scatter([], [], s=25)
scat_cue   = ax.scatter([], [], s=250, facecolors='none', edgecolors='gold', linewidths=1.8)  # yellow ring
scat_shock = ax.scatter([], [], s=80, marker='x', c='magenta', linewidths=2.0)               # magenta X

texts = [ax.text(0, 0, "", fontsize=6) for _ in range(NUM_COWS)]
count_text = ax.text(FIELD_SIZE / 2, FIELD_SIZE + 6, "", fontsize=10, color='black', ha='center',
                     bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))

for gx, gy, w, h in grazing_patches:
    ax.add_patch(patches.Rectangle((gx, gy), w, h, color='lightgreen', alpha=0.3))
fence_color = (1, 0, 0, 0.1)
ax.add_patch(plt.Rectangle((0, 0), FENCE_TRIGGER, FIELD_SIZE, color=fence_color))
ax.add_patch(plt.Rectangle((FIELD_SIZE - FENCE_TRIGGER, 0), FENCE_TRIGGER, FIELD_SIZE, color=fence_color))
ax.add_patch(plt.Rectangle((0, 0), FIELD_SIZE, FENCE_TRIGGER, color=fence_color))
ax.add_patch(plt.Rectangle((0, FIELD_SIZE - FENCE_TRIGGER), FIELD_SIZE, FENCE_TRIGGER, color=fence_color))

legend_patches = [
    Patch(color='green', label='Grazing'),
    Patch(color='blue', label='Walking'),
    Patch(color='red', label='Reacting'),
]
cue_handle   = Line2D([0], [0], marker='o', linestyle='None', markerfacecolor='none',
                      markeredgecolor='gold', markeredgewidth=1.8, markersize=10, label='Audio cue')
shock_handle = Line2D([0], [0], marker='x', linestyle='None', color='magenta',
                      markeredgewidth=2.0, markersize=8, label='Electric shock')

ax.legend(handles=legend_patches + [cue_handle, shock_handle], loc='lower left')
ax.set_xlim(0, FIELD_SIZE)
ax.set_ylim(0, FIELD_SIZE + 10)
ax.set_aspect('equal')
ax.set_xticks([]); ax.set_yticks([])
ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)

def update(frame):
    scat.set_offsets(trajectory[frame])
    scat.set_color(state_colors[frame])

    cue_pts = cue_marker_positions_per_frame[frame]
    shock_pts = shock_marker_positions_per_frame[frame]
    if cue_pts.size:
        scat_cue.set_offsets(cue_pts);   scat_cue.set_visible(True)
    else:
        scat_cue.set_offsets(np.empty((0,2))); scat_cue.set_visible(False)
    if shock_pts.size:
        scat_shock.set_offsets(shock_pts); scat_shock.set_visible(True)
    else:
        scat_shock.set_offsets(np.empty((0,2))); scat_shock.set_visible(False)

    for i, text in enumerate(texts):
        text.set_position(trajectory[frame][i])
        text.set_text(cow_labels[frame][i])
    grazing, walking, reacting = behavior_counts[frame]
    count_text.set_text(f"Grazing: {grazing} | Walking: {walking} | Reacting: {reacting}")
    return scat, scat_cue, scat_shock, *texts, count_text

ani = animation.FuncAnimation(fig, update, frames=STEPS, interval=40)

Writer = animation.FFMpegWriter(
    fps=25, codec="libx264",
    extra_args=["-pix_fmt", "yuv420p", "-crf", "17", "-preset", "slow"]
)
ani.save("simulation 3 with section 1 equations.mp4", writer=Writer, dpi=200)

#simulation 3 with section 1 equations
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import matplotlib.patches as patches
from matplotlib.patches import Patch

# --- Constants ---
NUM_COWS = 60
FIELD_SIZE = 80
DT = 0.2
STEPS = 500

# --- Behavior States ---
STATE_GRAZING = 0
STATE_WALKING = 1
STATE_REACTING = 2

# --- Parameters ---
MAX_SPEED = 0.7
TURN_LIMIT = 0.2
VISUAL_RANGE = 14
DESIRED_SPACING = 4.0
FENCE_TRIGGER = 12
FENCE_REACT_TIME = 15

# --- Bio-Informed Parameters ---
f = 8000  # Hz
A = 80    # dB
sigma_f = 1000
A50 = 70
s = 0.3
gamma = 0.1
t50 = 25
lambda_ = 0.05
k1 = 1.0
k2 = 10.0
theta = 0.5
N_val = 1.0

# --- Electric Shock Parameters ---
SHOCK_ZONE = 16.0  # Distance from edge to trigger potential shock
WARNING_ZONE = 22.0 # Distance from edge for warning cue
SHOCK_IMPULSE = 2.0 # Magnitude of impulse when shocked
SHOCK_REACT_STEPS = 12 # How long cow is in reacting state after shock
SHOCK_REFRACT_STEPS = 35 # Minimum steps between shocks for a cow
MIN_CUE_TO_SHOCK_STEPS = 5 # Minimum steps in warning zone after cue before shock is possible

TRAINING_STEPS = 150 # Steps considered the 'training' phase
DAY_STEPS = 500 # Simulation steps per 'day' for rate calculations

# Target shock rates
TARGET_TRAIN_MIN = 1.0 # shocks/cow/day
TARGET_TRAIN_MAX = 6.5 # shocks/cow/day
TARGET_POST_MIN = 0.06 # shocks/cow/day
TARGET_POST_MAX = 0.12 # shocks/cow/day
TARGET_POST_ESC_MIN = 10.0 # % of cues escalating to shock
TARGET_POST_ESC_MAX = 30.0 # % of cues escalating to shock

# Autocalibration parameters
CALIBRATION_WINDOW = 50 # Steps for rate calculation window
CUE_COOLDOWN_STEPS = 12 # Steps after a cue is given before another can be given

# --- Initialization ---
np.random.seed(42)
positions = np.random.rand(NUM_COWS, 2) * 50 + 10
angles = np.random.rand(NUM_COWS) * 2 * np.pi
velocities = np.stack((np.cos(angles), np.sin(angles)), axis=1) * 0.5
states = np.full(NUM_COWS, STATE_GRAZING)
state_timers = np.random.randint(20, 60, size=NUM_COWS)
cooldown_timer = np.zeros(NUM_COWS, dtype=int)
arousal = np.zeros(NUM_COWS)
fence_timers = np.zeros(NUM_COWS)
in_recovery = np.zeros(NUM_COWS, dtype=bool)
cooldown_timer = np.zeros(NUM_COWS, dtype=int)

# --- Traits ---
fopt = np.random.normal(8000, 100, NUM_COWS)
reaction_threshold = np.random.uniform(0.7, 1.2, NUM_COWS)
wander_bias = np.random.uniform(0.05, 0.25, NUM_COWS)
social_strength = np.random.uniform(0.3, 1.0, NUM_COWS)
group_influence = np.random.uniform(0.8, 1.3, NUM_COWS)

# --- Social Bonds ---
SOCIAL_PAIRS = [(i, i+1) for i in range(0, NUM_COWS-1, 2)]
social_matrix = np.zeros((NUM_COWS, NUM_COWS))
for i, j in SOCIAL_PAIRS:
    social_matrix[i, j] = social_matrix[j, i] = 1

# --- Grazing Patches ---
grazing_patches = [(20, 20, 15, 10), (40, 50, 20, 15), (60, 15, 10, 10)]

# --- Buffers ---
trajectory = []
state_colors = []
cow_labels = []
behavior_counts = []

# --- Shock Tracking ---
shocks_given_history = [] # To store shocks given at each step for calibration
cue_given_history = [] # To store cues given at each step for calibration

shocks_given = np.zeros(NUM_COWS, dtype=int)
shock_refractory = np.zeros(NUM_COWS, dtype=int)
cue_timers = np.full(NUM_COWS, -1, dtype=int) # -1 indicates no cue
total_shocks = 0
cues_escalated = 0
total_cues = 0 # Initialize total_cues as well

# Autocalibration variables
p_shock = 0.01 # Initial probability of shock given conditions met
p_escalate = 0.1 # Initial probability of cue escalation
p_turn_cap = 0.5 # Cows are less likely to turn in shock zone

# --- Main Simulation Loop ---
for step in range(STEPS):
    frame_colors = []
    labels = []
    accelerations = np.zeros_like(velocities)
    grazing_count, walking_count, reacting_count = 0, 0, 0
    shocks_this_step = 0
    cues_this_step = 0

    # Autocalibration Check
    if step > 0 and step % CALIBRATION_WINDOW == 0:
        # Calculate metrics over the last CALIBRATION_WINDOW steps
        start_step = max(0, step - CALIBRATION_WINDOW)
        window_shocks = sum(shocks_given_history[start_step:step])
        window_cues = sum(cue_given_history[start_step:step])


        # Shock rate calculation (shocks per cow per day)
        window_duration_days = CALIBRATION_WINDOW / DAY_STEPS
        if window_duration_days > 0:
            current_shock_rate = window_shocks / NUM_COWS / window_duration_days
        else:
            current_shock_rate = 0

        # Cue escalation rate calculation
        # Need to track escalated cues specifically within the window
        # For now, approximate based on total escalated vs total cues
        # A better approach would be to track escalated cues history similar to shocks/cues given
        current_escalation_rate = (cues_escalated / total_cues) * 100 if total_cues > 0 else 0


        # Adjust p_shock and p_escalate (basic proportional control)
        if step < TRAINING_STEPS:
            # Training phase
            if current_shock_rate < TARGET_TRAIN_MIN:
                p_shock += 0.005 # Smaller adjustment
            elif current_shock_rate > TARGET_TRAIN_MAX:
                p_shock -= 0.005 # Smaller adjustment
        else:
            # Post-learning phase
            if current_shock_rate < TARGET_POST_MIN:
                p_shock += 0.0005 # Even smaller adjustment
            elif current_shock_rate > TARGET_POST_MAX:
                p_shock -= 0.0005 # Even smaller adjustment

            if current_escalation_rate < TARGET_POST_ESC_MIN:
                 p_escalate += 0.002 # Smaller adjustment
            elif current_escalation_rate > TARGET_POST_ESC_MAX:
                 p_escalate -= 0.002 # Smaller adjustment

        p_shock = np.clip(p_shock, 0.0001, 0.2) # Keep probability within reasonable bounds
        p_escalate = np.clip(p_escalate, 0.01, 0.5) # Keep probability within reasonable bounds


    for i in range(NUM_COWS):
        pos_i = positions[i]
        vel_i = velocities[i]
        state = states[i]

        # --- Herd Forces ---
        sep, coh, align, bond = np.zeros(2), np.zeros(2), np.zeros(2), np.zeros(2)
        count, bond_count = 0, 0

        for j in range(NUM_COWS):
            if i == j:
                continue
            offset = positions[j] - pos_i
            dist = np.linalg.norm(offset)
            if dist < VISUAL_RANGE and dist > 1e-4:
                direction = offset / dist
                if dist < DESIRED_SPACING:
                    sep += ((DESIRED_SPACING - dist)**2) * (-direction)
                elif dist < DESIRED_SPACING * 2:
                    sep += 0.1 * (1 - dist / (DESIRED_SPACING * 2)) * (-direction)
                coh += (offset * np.clip((dist - DESIRED_SPACING) / VISUAL_RANGE, 0, 1))
                align += velocities[j]
                count += 1
                if social_matrix[i, j]:
                    bond += offset
                    bond_count += 1

        if count > 0:
            coh = coh / count - vel_i
            align = align / count - vel_i
        if bond_count > 0:
            bond = bond / bond_count - vel_i * social_strength[i]

        # --- Fence Avoidance ---
        avoid = np.zeros(2)
        in_fence_zone = False
        if pos_i[0] < FENCE_TRIGGER:
            avoid += np.array([1.0, 0.0])
            in_fence_zone = True
        elif pos_i[0] > FIELD_SIZE - FENCE_TRIGGER:
            avoid += np.array([-1.0, 0.0])
            in_fence_zone = True
        if pos_i[1] < FENCE_TRIGGER:
            avoid += np.array([0.0, 1.0])
            in_fence_zone = True
        elif pos_i[1] > FIELD_SIZE - FENCE_TRIGGER: # Corrected typo here
            avoid += np.array([0.0, -1.0])
            in_fence_zone = True
        fence_timers[i] = fence_timers[i] + 1 if in_fence_zone else 0

        # --- Arousal ---
        for j in range(NUM_COWS):
            if j != i and np.linalg.norm(positions[j] - pos_i) < 10.0:
                arousal[i] += 0.05 * arousal[j]
        arousal[i] = np.clip(arousal[i] * 0.95, 0, 1.5)

        # --- Grazing Attraction ---
        patch_pull = np.zeros(2)
        if state == STATE_GRAZING:
            for gx, gy, w, h in grazing_patches:
                center = np.array([gx + w/2, gy + h/2])
                dist = np.linalg.norm(center - pos_i)
                if dist < 30:
                    patch_pull += 0.2 * (center - pos_i) / (dist + 1e-4)

        # --- Drift & Wander ---
        edge_bias = np.zeros(2)
        if step % 200 < 50 and i % 10 == 0:
            edge_bias = np.random.uniform(-1, 1, size=2)
            edge_bias /= np.linalg.norm(edge_bias) + 1e-4
            edge_bias *= 0.4
        wander = wander_bias[i] * np.random.uniform(-1, 1, size=2) + edge_bias
        drift = np.array([np.sin(0.01 * step), np.cos(0.01 * step)]) * 0.1

        # --- Bio-Informed Reactivity ---
        F_f = np.exp(-((f - fopt[i])**2) / (2 * sigma_f**2))
        S_A = 1 / (1 + np.exp(-s * (A - A50)))
        L_t = 1 / (1 + np.exp(-gamma * (step - t50)))
        H_t = np.exp(-lambda_ * step)
        M_t = k1 * F_f * S_A * H_t * N_val
        P_turn_raw = 1 / (1 + np.exp(-group_influence[i] * k2 * (S_A * F_f * L_t - theta)))

        # Cap turn probability based on state/zone
        P_turn = P_turn_raw
        in_shock_zone = pos_i[0] < SHOCK_ZONE or pos_i[0] > FIELD_SIZE - SHOCK_ZONE or pos_i[1] < SHOCK_ZONE or pos_i[1] > FIELD_SIZE - SHOCK_ZONE
        if in_shock_zone:
            P_turn = np.clip(P_turn_raw, 0, p_turn_cap) # Less likely to turn in shock zone


        # --- Shock Logic ---
        in_warning_zone = pos_i[0] < WARNING_ZONE or pos_i[0] > FIELD_SIZE - WARNING_ZONE or pos_i[1] < WARNING_ZONE or pos_i[1] > FIELD_SIZE - WARNING_ZONE
        moving_toward_edge = (pos_i[0] < WARNING_ZONE and vel_i[0] < 0) or \
                             (pos_i[0] > FIELD_SIZE - WARNING_ZONE and vel_i[0] > 0) or \
                             (pos_i[1] < WARNING_ZONE and vel_i[1] < 0) or \
                             (pos_i[1] > FIELD_SIZE - WARNING_ZONE and vel_i[1] > 0)

        # Start or continue cue timer if in warning zone and moving towards edge and not reacting or in refractory
        if in_warning_zone and moving_toward_edge and state != STATE_REACTING and shock_refractory[i] <= 0:
            if cue_timers[i] == -1:
                cue_timers[i] = 0 # Start timer
                # Here is where a cue would be given (e.g., audio played)
                cues_this_step += 1 # Count this as a cue event in this step
            else:
                cue_timers[i] += 1 # Continue timer
        else:
            cue_timers[i] = -1 # Reset timer if conditions not met

        # Shock possibility if timer exceeds threshold and not in refractory
        if cue_timers[i] >= MIN_CUE_TO_SHOCK_STEPS and shock_refractory[i] <= 0:
             # Determine if shock escalates
             if np.random.rand() < p_escalate:
                  # Determine if shock is given based on p_shock
                  if np.random.rand() < p_shock:
                       states[i] = STATE_REACTING
                       state_timers[i] = SHOCK_REACT_STEPS
                       velocities[i] = -velocities[i] * SHOCK_IMPULSE # Apply impulse
                       shocks_given[i] += 1 # Increment shock count for this cow (not step)
                       shocks_this_step += 1 # Count shock in this step for calibration history
                       total_shocks += 1
                       shock_refractory[i] = SHOCK_REFRACT_STEPS
                       cues_escalated += 1 # Count this as an escalated cue
                       cue_timers[i] = -1 # Reset cue timer after shock
                  #else:
                      # If escalated but no shock, reset cue timer? Depends on desired behavior.
                      # For now, let's reset.
                      #cue_timers[i] = -1
             #else:
                  # If not escalated, reset cue timer
                  #cue_timers[i] = -1

        # Decrease refractory timer
        if shock_refractory[i] > 0:
            shock_refractory[i] -= 1


        # --- Acceleration by State ---
        if state == STATE_GRAZING:
            acc = 0.6 * sep + 0.3 * patch_pull + 0.1 * drift
            color = 'green'
            grazing_count += 1
        elif state == STATE_WALKING:
            acc = 0.6 * sep + 0.2 * coh + 0.2 * drift + 0.1 * bond
            color = 'blue'
            walking_count += 1
        elif state == STATE_REACTING:
            acc = 1.0 * sep + 0.6 * avoid + 0.2 * bond
            color = 'red'
            reacting_count += 1

        # Apply turning based on P_turn
        if np.random.rand() < P_turn:
             acc += -vel_i * 0.5 # Simple turn around

        acc += M_t * wander
        frame_colors.append(color)
        labels.append(str(i))

        # --- Velocity Update ---
        desired_heading = vel_i + acc * DT
        if np.linalg.norm(desired_heading) > 1e-4:
            desired_heading /= np.linalg.norm(desired_heading)
        angle_diff = np.arctan2(desired_heading[1], desired_heading[0]) - np.arctan2(vel_i[1], vel_i[0])
        angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi
        angle_diff = np.clip(angle_diff, -TURN_LIMIT, TURN_LIMIT)
        new_angle = np.arctan2(vel_i[1], vel_i[0]) + angle_diff
        speed_factor = 0.4 if state == STATE_GRAZING else 1.0
        velocities[i] = np.array([np.cos(new_angle), np.sin(new_angle)]) * MAX_SPEED * speed_factor
        positions[i] += velocities[i] * DT
        positions[i] = np.clip(positions[i], 0, FIELD_SIZE)

        # --- State Transitions ---
        state_timers[i] -= 1

        if states[i] == STATE_REACTING:
            if state_timers[i] <= 0:
                # Exit reacting state into cooldown
                in_recovery[i] = True
                cooldown_timer[i] = np.random.randint(20, 40)
                states[i] = np.random.choice([STATE_GRAZING, STATE_WALKING])
                state_timers[i] = np.random.randint(30, 80)

        elif in_recovery[i]:
            cooldown_timer[i] -= 1
            if cooldown_timer[i] <= 0:
                in_recovery[i] = False  # Recovery done, normal behavior resumes

        # Original reaction trigger (keep for other stimuli)
        elif fence_timers[i] > FENCE_REACT_TIME or arousal[i] > reaction_threshold[i]:
            # Only trigger if not already in reaction from shock and not in refractory
            if state != STATE_REACTING and shock_refractory[i] <= 0:
                states[i] = STATE_REACTING
                state_timers[i] = 10


        elif state_timers[i] <= 0:
            states[i] = np.random.choice([STATE_GRAZING, STATE_WALKING])
            state_timers[i] = np.random.randint(30, 80)


    shocks_given_history.append(shocks_this_step)
    cue_given_history.append(cues_this_step)
    trajectory.append(positions.copy())
    state_colors.append(frame_colors)
    cow_labels.append(labels)
    behavior_counts.append((grazing_count, walking_count, reacting_count))

# --- Visualization ---
fig, ax = plt.subplots()
scat = ax.scatter([], [], s=25)
texts = [ax.text(0, 0, "", fontsize=6) for _ in range(NUM_COWS)]
count_text = ax.text(FIELD_SIZE / 2, FIELD_SIZE + 6, "", fontsize=10, color='black', ha='center',
                     bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))

# Add warning and shock zones to plot
warning_color = (1, 1, 0, 0.1) # Light yellow
shock_color = (1, 0.5, 0, 0.1) # Light orange

ax.add_patch(plt.Rectangle((0, 0), WARNING_ZONE, FIELD_SIZE, color=warning_color))
ax.add_patch(plt.Rectangle((FIELD_SIZE - WARNING_ZONE, 0), WARNING_ZONE, FIELD_SIZE, color=warning_color))
ax.add_patch(plt.Rectangle((0, 0), FIELD_SIZE, WARNING_ZONE, color=warning_color))
ax.add_patch(plt.Rectangle((0, FIELD_SIZE - WARNING_ZONE), FIELD_SIZE, WARNING_ZONE, color=warning_color))

ax.add_patch(plt.Rectangle((0, 0), SHOCK_ZONE, FIELD_SIZE, color=shock_color))
ax.add_patch(plt.Rectangle((FIELD_SIZE - SHOCK_ZONE, 0), SHOCK_ZONE, FIELD_SIZE, color=shock_color))
ax.add_patch(plt.Rectangle((0, 0), FIELD_SIZE, SHOCK_ZONE, color=shock_color))
ax.add_patch(plt.Rectangle((0, FIELD_SIZE - SHOCK_ZONE), FIELD_SIZE, SHOCK_ZONE, color=shock_color))


for gx, gy, w, h in grazing_patches:
    ax.add_patch(patches.Rectangle((gx, gy), w, h, color='lightgreen', alpha=0.3))
fence_color = (1, 0, 0, 0.1)
ax.add_patch(plt.Rectangle((0, 0), FENCE_TRIGGER, FIELD_SIZE, color=fence_color))
ax.add_patch(plt.Rectangle((FIELD_SIZE - FENCE_TRIGGER, 0), FENCE_TRIGGER, FIELD_SIZE, color=fence_color))
ax.add_patch(plt.Rectangle((0, 0), FIELD_SIZE, FENCE_TRIGGER, color=fence_color))
ax.add_patch(plt.Rectangle((0, FIELD_SIZE - FENCE_TRIGGER), FIELD_SIZE, FENCE_TRIGGER, color=fence_color))

legend_patches = [
    Patch(color='green', label='Grazing'),
    Patch(color='blue', label='Walking'),
    Patch(color='red', label='Reacting'),
    Patch(color=warning_color, label='Warning Zone'),
    Patch(color=shock_color, label='Shock Zone'),
]
ax.legend(handles=legend_patches, loc='lower left')
ax.set_xlim(0, FIELD_SIZE)
ax.set_ylim(0, FIELD_SIZE + 10)
ax.set_aspect('equal')

ax.set_xticks([])
ax.set_yticks([])
ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)

def update(frame):
    scat.set_offsets(trajectory[frame])
    scat.set_color(state_colors[frame])
    for i, text in enumerate(texts):
        text.set_position(trajectory[frame][i])
        text.set_text(cow_labels[frame][i])
    grazing, walking, reacting = behavior_counts[frame]
    # Display shock counts as well
    # Use shocks_given_history to accurately show shocks *up to* the current frame
    current_total_shocks = sum(shocks_given_history[:frame+1])
    count_text.set_text(f"Grazing: {grazing} | Walking: {walking} | Reacting: {reacting} | Total Shocks: {current_total_shocks}")
    return scat, *texts, count_text

ani = animation.FuncAnimation(fig, update, frames=STEPS, interval=40)
ani.save("simulation_with_shock.mp4", writer="ffmpeg", fps=25)
plt.show()

# sim3_scenarios.py
# Continuous-time cattle simulation with audio→shock gating, training/post phases,
# optional warmup, overlays, scenario runner, and high-quality video output.

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import matplotlib.patches as patches
from matplotlib.patches import Patch
from matplotlib.lines import Line2D
from dataclasses import dataclass, asdict
from copy import deepcopy

# -------------- Config dataclass --------------

@dataclass
class SimConfig:
    # Core arena/time
    NUM_COWS: int = 60
    FIELD_SIZE: float = 80.0
    DT: float = 0.2
    STEPS: int = 500

    # States
    STATE_GRAZING: int = 0
    STATE_WALKING: int = 1
    STATE_REACTING: int = 2

    # Movement/vision
    MAX_SPEED: float = 0.7
    TURN_LIMIT: float = 0.2
    VISUAL_RANGE: float = 14.0
    DESIRED_SPACING: float = 4.0

    # Fence/warning band
    FENCE_TRIGGER: float = 16.0
    FENCE_REACT_TIME: int = 15

    # Bio params (Section 1)
    f: float = 8000.0
    A: float = 80.0
    sigma_f: float = 1000.0
    A50: float = 70.0
    s: float = 0.3
    gamma: float = 0.1
    t50: float = 25.0
    lambda_: float = 0.05
    k1: float = 1.0
    k2: float = 10.0
    theta: float = 0.5
    N_val: float = 1.0

    # Phases
    TRAIN_FRACTION: float = 0.30

    # Targets (per cow per "day" = STEPS)
    TARGET_TRAIN_LOW: float = 1.0
    TARGET_TRAIN_HIGH: float = 6.5
    TARGET_POST_LOW: float = 0.06
    TARGET_POST_HIGH: float = 0.12

    # Post escalation bounds
    POST_ESCALATE_FRAC_MIN: float = 0.20
    POST_ESCALATE_FRAC_MAX: float = 0.30

    # Logistics
    CUE_GRACE_STEPS: int = 4
    SHOCK_REFRACTORY: int = 10
    MAX_SHOCKS_PER_CUE: int = 1
    SHOCK_MARKER_DUR: int = 12

    # Controller gains
    GAIN_UNDER: float = 1.10
    GAIN_OVER: float = 0.92
    ESC_INIT_TRAIN: float = 0.85
    ESC_INIT_POST: float = 0.22

    # Probing (training)
    TRAIN_OUTWARD_BIAS: float = 0.22
    TRAIN_PROBE_PERIOD: int = 45
    TRAIN_PROBE_DUR: int = 14
    TRAIN_PROBE_PUSH: float = 0.40
    TRAIN_PROBE_GROUPS: int = 6

    # Probing (post)
    POST_OUTWARD_BIAS_NEAREST: float = 0.18   # toward nearest edge
    POST_OUTWARD_BIAS_CENTER: float = 0.18    # outward from center
    EDGE_PROBE_PERIOD: int = 50
    EDGE_PROBE_DUR: int = 16
    EDGE_PROBE_PUSH: float = 0.35
    EDGE_PROBE_GROUPS: int = 6

    # Warmup (optional: keep cows away from band; avoid step-4 piles)
    WARMUP_STEPS: int = 0     # set to 6 if you want the smoother start
    INITIAL_MARGIN_EXTRA: float = 4.0

    # Grazing patches (x, y, w, h)
    grazing_patches: tuple = ((20, 20, 15, 10), (40, 50, 20, 15), (60, 15, 10, 10))

    # Video/visuals
    MAKE_VIDEO: bool = True
    VIDEO_FPS: int = 25
    FIGSIZE: float = 6.0
    DPI: int = 200
    BITRATE: int = 9000
    FILENAME: str = "sim3_baseline.mp4"

# -------------- Simulation --------------

def run_sim(cfg: SimConfig, seed: int = 42):
    np.random.seed(seed)

    TRAIN_STEPS = int(cfg.STEPS * cfg.TRAIN_FRACTION)

    # Traits / initial state
    # Optional: keep initial cows out of fence zone if WARMUP_STEPS>0
    if cfg.WARMUP_STEPS > 0:
        margin = max(cfg.FENCE_TRIGGER, 16.0) + cfg.INITIAL_MARGIN_EXTRA
        positions = np.random.rand(cfg.NUM_COWS, 2) * (cfg.FIELD_SIZE - 2 * margin) + margin
    else:
        positions = np.random.rand(cfg.NUM_COWS, 2) * 50 + 10

    angles = np.random.rand(cfg.NUM_COWS) * 2 * np.pi
    velocities = np.stack((np.cos(angles), np.sin(angles)), axis=1) * 0.5
    states = np.full(cfg.NUM_COWS, cfg.STATE_GRAZING)
    state_timers = np.random.randint(20, 60, size=cfg.NUM_COWS)
    cooldown_timer = np.zeros(cfg.NUM_COWS, dtype=int)
    arousal = np.zeros(cfg.NUM_COWS)
    fence_timers = np.zeros(cfg.NUM_COWS)
    in_recovery = np.zeros(cfg.NUM_COWS, dtype=bool)

    fopt = np.random.normal(8000, 100, cfg.NUM_COWS)
    reaction_threshold = np.random.uniform(0.7, 1.2, cfg.NUM_COWS)
    wander_bias = np.random.uniform(0.05, 0.25, cfg.NUM_COWS)
    social_strength = np.random.uniform(0.3, 1.0, cfg.NUM_COWS)
    group_influence = np.random.uniform(0.8, 1.3, cfg.NUM_COWS)

    # Social bonds (pairs)
    SOCIAL_PAIRS = [(i, i + 1) for i in range(0, cfg.NUM_COWS - 1, 2)]
    social_matrix = np.zeros((cfg.NUM_COWS, cfg.NUM_COWS))
    for i, j in SOCIAL_PAIRS:
        social_matrix[i, j] = social_matrix[j, i] = 1

    # --- Audio cue / shock tracking ---
    pending_cue_until = np.zeros(cfg.NUM_COWS, dtype=int)
    cue_open = np.zeros(cfg.NUM_COWS, dtype=bool)
    refractory = np.zeros(cfg.NUM_COWS, dtype=int)

    # --- Logging / metrics ---
    shock_log = []
    cue_counter = 0
    last_cue_id = np.full(cfg.NUM_COWS, -1)
    total_cues = total_shocks = 0
    train_cues = post_cues = 0
    train_shocks = post_shocks = 0
    train_escalations = post_escalations = 0

    # Adaptive escalation probabilities
    p_escalate_train = cfg.ESC_INIT_TRAIN
    p_escalate_post = cfg.ESC_INIT_POST

    # --- Visualization buffers (only if making video) ---
    if cfg.MAKE_VIDEO:
        trajectory = []
        state_colors = []
        cow_labels = []
        behavior_counts = []
        cue_marker_positions_per_frame = []
        shock_marker_positions_per_frame = []
        shock_flash_schedule = []

    # Helpers
    def away_from_nearest_edge(pos, field=cfg.FIELD_SIZE):
        d = np.array([pos[0], field - pos[0], pos[1], field - pos[1]])  # left, right, bottom, top
        edge = np.argmin(d)
        if edge == 0:   return np.array([ 1.0,  0.0])
        if edge == 1:   return np.array([-1.0,  0.0])
        if edge == 2:   return np.array([ 0.0,  1.0])
        return np.array([ 0.0, -1.0])

    center = np.array([cfg.FIELD_SIZE / 2, cfg.FIELD_SIZE / 2])

    # --- Main loop ---
    for step in range(cfg.STEPS):
        in_training_phase = (step < TRAIN_STEPS)
        steps_elapsed = max(step, 1)
        days_elapsed = steps_elapsed / cfg.STEPS
        obs_shocks_per_cow_day = (total_shocks / max(cfg.NUM_COWS, 1)) / max(days_elapsed, 1e-6)

        # Closed-loop adjust
        if in_training_phase:
            if obs_shocks_per_cow_day < cfg.TARGET_TRAIN_LOW:
                p_escalate_train *= cfg.GAIN_UNDER
            elif obs_shocks_per_cow_day > cfg.TARGET_TRAIN_HIGH:
                p_escalate_train *= cfg.GAIN_OVER
            p_escalate_train = float(np.clip(p_escalate_train, 0.02, 0.95))
        else:
            if obs_shocks_per_cow_day < cfg.TARGET_POST_LOW:
                p_escalate_post *= cfg.GAIN_UNDER
            elif obs_shocks_per_cow_day > cfg.TARGET_POST_HIGH:
                p_escalate_post *= cfg.GAIN_OVER
            p_escalate_post = float(np.clip(p_escalate_post,
                                            cfg.POST_ESCALATE_FRAC_MIN,
                                            cfg.POST_ESCALATE_FRAC_MAX))

        # per-frame viz tallies
        if cfg.MAKE_VIDEO:
            frame_colors = []
            labels = []
            grazing_count = walking_count = reacting_count = 0

        # Dynamics update
        for i in range(cfg.NUM_COWS):
            pos_i = positions[i]
            vel_i = velocities[i]
            state = states[i]

            # Refractory
            if refractory[i] > 0:
                refractory[i] -= 1

            # Boids-like forces
            sep = np.zeros(2); coh = np.zeros(2); align = np.zeros(2); bond = np.zeros(2)
            count = 0; bond_count = 0
            for j in range(cfg.NUM_COWS):
                if i == j: continue
                offset = positions[j] - pos_i
                dist = np.linalg.norm(offset)
                if dist < cfg.VISUAL_RANGE and dist > 1e-4:
                    direction = offset / dist
                    if dist < cfg.DESIRED_SPACING:
                        sep += ((cfg.DESIRED_SPACING - dist) ** 2) * (-direction)
                    elif dist < cfg.DESIRED_SPACING * 2:
                        sep += 0.1 * (1 - dist / (cfg.DESIRED_SPACING * 2)) * (-direction)
                    coh += (offset * np.clip((dist - cfg.DESIRED_SPACING) / cfg.VISUAL_RANGE, 0, 1))
                    align += velocities[j]
                    count += 1
                    if social_matrix[i, j]:
                        bond += offset
                        bond_count += 1
            if count > 0:
                coh = coh / count - vel_i
                align = align / count - vel_i
            if bond_count > 0:
                bond = bond / bond_count - vel_i * social_strength[i]

            # Fence avoidance & timers
            avoid = np.zeros(2)
            in_fence_zone = False
            if pos_i[0] < cfg.FENCE_TRIGGER:
                avoid += np.array([1.0, 0.0]); in_fence_zone = True
            elif pos_i[0] > cfg.FIELD_SIZE - cfg.FENCE_TRIGGER:
                avoid += np.array([-1.0, 0.0]); in_fence_zone = True
            if pos_i[1] < cfg.FENCE_TRIGGER:
                avoid += np.array([0.0, 1.0]); in_fence_zone = True
            elif pos_i[1] > cfg.FIELD_SIZE - cfg.FENCE_TRIGGER:
                avoid += np.array([0.0, -1.0]); in_fence_zone = True

            fence_timers[i] = fence_timers[i] + 1 if in_fence_zone else 0

            # AUDIO CUE TRIGGER (suppress during warmup)
            if step >= cfg.WARMUP_STEPS and fence_timers[i] == 1:
                cue_open[i] = True
                pending_cue_until[i] = step + cfg.CUE_GRACE_STEPS
                total_cues += 1
                cue_counter += 1
                last_cue_id[i] = cue_counter
                if in_training_phase:  train_cues += 1
                else:                  post_cues += 1

            # Arousal contagion
            for j in range(cfg.NUM_COWS):
                if j != i and np.linalg.norm(positions[j] - pos_i) < 10.0:
                    arousal[i] += 0.05 * arousal[j]
            arousal[i] = np.clip(arousal[i] * 0.95, 0, 1.5)

            # Grazing attraction
            patch_pull = np.zeros(2)
            if state == cfg.STATE_GRAZING:
                for gx, gy, w, h in cfg.grazing_patches:
                    center_patch = np.array([gx + w / 2, gy + h / 2])
                    dist = np.linalg.norm(center_patch - pos_i)
                    if dist < 30:
                        patch_pull += 0.2 * (center_patch - pos_i) / (dist + 1e-4)

            # Drift & wander
            edge_bias = np.zeros(2)
            if step % 200 < 50 and i % 10 == 0:
                edge_bias = np.random.uniform(-1, 1, size=2)
                edge_bias /= np.linalg.norm(edge_bias) + 1e-4
                edge_bias *= 0.4
            wander = wander_bias[i] * np.random.uniform(-1, 1, size=2) + edge_bias
            drift = np.array([np.sin(0.01 * step), np.cos(0.01 * step)]) * 0.1

            # Training probes
            if in_training_phase:
                to_edge = -away_from_nearest_edge(pos_i)
                drift += cfg.TRAIN_OUTWARD_BIAS * to_edge
                grp = (step // cfg.TRAIN_PROBE_PERIOD) % cfg.TRAIN_PROBE_GROUPS
                if (step % cfg.TRAIN_PROBE_PERIOD) < cfg.TRAIN_PROBE_DUR and (i % cfg.TRAIN_PROBE_GROUPS) == grp:
                    drift += cfg.TRAIN_PROBE_PUSH * to_edge

            # Post-phase probes (two complementary nudges: to nearest edge & outward from center)
            if not in_training_phase:
                to_edge = -away_from_nearest_edge(pos_i)
                drift += cfg.POST_OUTWARD_BIAS_NEAREST * to_edge
                grp = (step // cfg.EDGE_PROBE_PERIOD) % cfg.EDGE_PROBE_GROUPS
                if (step % cfg.EDGE_PROBE_PERIOD) < cfg.EDGE_PROBE_DUR and (i % cfg.EDGE_PROBE_GROUPS) == grp:
                    drift += cfg.EDGE_PROBE_PUSH * to_edge

                outward = pos_i - center
                norm = np.linalg.norm(outward) + 1e-8
                outward /= norm
                drift += cfg.POST_OUTWARD_BIAS_CENTER * outward
                if (step % cfg.EDGE_PROBE_PERIOD) < cfg.EDGE_PROBE_DUR:
                    group_id = (step // cfg.EDGE_PROBE_DUR) % cfg.EDGE_PROBE_GROUPS
                    if (i % cfg.EDGE_PROBE_GROUPS) == group_id:
                        drift += cfg.EDGE_PROBE_PUSH * outward

            # Bio-informed reactivity
            F_f = np.exp(-((cfg.f - fopt[i]) ** 2) / (2 * cfg.sigma_f ** 2))
            S_A = 1 / (1 + np.exp(-cfg.s * (cfg.A - cfg.A50)))
            L_t = 1 / (1 + np.exp(-cfg.gamma * (step - cfg.t50)))
            H_t = np.exp(-cfg.lambda_ * step)
            M_t = cfg.k1 * F_f * S_A * H_t * cfg.N_val
            # P_turn kept for completeness; state machine uses arousal/fence
            _P_turn = 1 / (1 + np.exp(-group_influence[i] * cfg.k2 * (S_A * F_f * L_t - cfg.theta)))

            # Acceleration by state
            if state == cfg.STATE_GRAZING:
                acc = 0.6 * sep + 0.3 * patch_pull + 0.1 * drift
                if cfg.MAKE_VIDEO: frame_colors.append('green'); grazing_count += 1
            elif state == cfg.STATE_WALKING:
                acc = 0.6 * sep + 0.2 * coh + 0.2 * drift + 0.1 * bond
                if cfg.MAKE_VIDEO: frame_colors.append('blue'); walking_count += 1
            else:  # REACTING
                acc = 1.0 * sep + 0.6 * avoid + 0.2 * bond
                if cfg.MAKE_VIDEO: frame_colors.append('red'); reacting_count += 1

            acc += M_t * wander

            # Velocity / position update
            desired_heading = vel_i + acc * cfg.DT
            if np.linalg.norm(desired_heading) > 1e-4:
                desired_heading /= np.linalg.norm(desired_heading)
            angle_diff = np.arctan2(desired_heading[1], desired_heading[0]) - np.arctan2(vel_i[1], vel_i[0])
            angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi
            angle_diff = np.clip(angle_diff, -cfg.TURN_LIMIT, cfg.TURN_LIMIT)
            new_angle = np.arctan2(vel_i[1], vel_i[0]) + angle_diff
            speed_factor = 0.4 if state == cfg.STATE_GRAZING else 1.0
            velocities[i] = np.array([np.cos(new_angle), np.sin(new_angle)]) * cfg.MAX_SPEED * speed_factor
            positions[i] += velocities[i] * cfg.DT
            positions[i] = np.clip(positions[i], 0, cfg.FIELD_SIZE)

            # State transitions
            state_timers[i] -= 1
            if states[i] == cfg.STATE_REACTING:
                if state_timers[i] <= 0:
                    in_recovery[i] = True
                    cooldown_timer[i] = np.random.randint(20, 40)
                    states[i] = np.random.choice([cfg.STATE_GRAZING, cfg.STATE_WALKING])
                    state_timers[i] = np.random.randint(30, 80)
            elif in_recovery[i]:
                cooldown_timer[i] -= 1
                if cooldown_timer[i] <= 0:
                    in_recovery[i] = False
            elif fence_timers[i] > cfg.FENCE_REACT_TIME or arousal[i] > reaction_threshold[i]:
                states[i] = cfg.STATE_REACTING
                state_timers[i] = 10
            elif state_timers[i] <= 0:
                states[i] = np.random.choice([cfg.STATE_GRAZING, cfg.STATE_WALKING])
                state_timers[i] = np.random.randint(30, 80)

            # Cue resolution → potential shock
            if cue_open[i] and step >= pending_cue_until[i]:
                pos_now = positions[i].copy()
                still_in_warning = (
                    (pos_now[0] < cfg.FENCE_TRIGGER) or
                    (pos_now[0] > cfg.FIELD_SIZE - cfg.FENCE_TRIGGER) or
                    (pos_now[1] < cfg.FENCE_TRIGGER) or
                    (pos_now[1] > cfg.FIELD_SIZE - cfg.FENCE_TRIGGER)
                )
                if still_in_warning and refractory[i] == 0:
                    to_edge_vec = -away_from_nearest_edge(pos_now)  # toward edge
                    moving_toward_edge = np.dot(velocities[i], to_edge_vec) >= -0.01
                    if moving_toward_edge:
                        p = p_escalate_train if in_training_phase else p_escalate_post
                        if np.random.rand() < p:
                            total_shocks += 1
                            refractory[i] = cfg.SHOCK_REFRACTORY
                            phase = "training" if in_training_phase else "post"
                            # log
                            shock_log.append({
                                "step": step,
                                "time_s": step * cfg.DT,
                                "cow": i,
                                "phase": phase,
                                "cue_id": int(last_cue_id[i]),
                                "x": float(pos_now[0]),
                                "y": float(pos_now[1]),
                                "p_used": float(p)
                            })
                            if cfg.MAKE_VIDEO:
                                shock_flash_schedule.append((step, step + cfg.SHOCK_MARKER_DUR, i))
                            if in_training_phase:
                                train_shocks += 1
                                train_escalations += 1
                            else:
                                post_shocks += 1
                                post_escalations += 1
                # close window
                cue_open[i] = False
                pending_cue_until[i] = 0

            # labels
            if cfg.MAKE_VIDEO:
                labels.append(str(i))

        # Build per-frame overlays
        if cfg.MAKE_VIDEO:
            cue_positions = []
            for i in range(cfg.NUM_COWS):
                if cue_open[i] and step < pending_cue_until[i]:
                    cue_positions.append(positions[i].copy())
            cue_marker_positions_per_frame.append(np.array(cue_positions) if len(cue_positions) else np.empty((0, 2)))

            shock_positions = []
            for (start_s, end_s, cow_id) in shock_flash_schedule:
                if start_s <= step < end_s:
                    shock_positions.append(positions[cow_id].copy())
            shock_marker_positions_per_frame.append(np.array(shock_positions) if len(shock_positions) else np.empty((0, 2)))

            trajectory.append(positions.copy())
            state_colors.append(frame_colors)
            cow_labels.append(labels)
            behavior_counts.append((
                np.sum(np.array(state_colors[-1]) == 'green'),
                np.sum(np.array(state_colors[-1]) == 'blue'),
                np.sum(np.array(state_colors[-1]) == 'red')
            ))

    # --- Metrics ---
    def safe_div(a, b): return a / b if b > 0 else 0.0

    days_train = max(TRAIN_STEPS / cfg.STEPS, 1e-9)
    days_post  = max((cfg.STEPS - TRAIN_STEPS) / cfg.STEPS, 1e-9)
    train_rate = safe_div(train_shocks, cfg.NUM_COWS * days_train)
    post_rate  = safe_div(post_shocks,  cfg.NUM_COWS * days_post)
    overall_rate = safe_div(total_shocks, cfg.NUM_COWS * (cfg.STEPS / cfg.STEPS))
    overall_escal = safe_div(total_shocks, total_cues) * 100.0
    post_escal = safe_div(post_shocks, post_cues) * 100.0
    train_escal = safe_div(train_shocks, train_cues) * 100.0

    # Report
    metrics = {
        "total_cues": int(total_cues),
        "total_shocks": int(total_shocks),
        "train_shocks": int(train_shocks),
        "post_shocks": int(post_shocks),
        "train_cues": int(train_cues),
        "post_cues": int(post_cues),
        "overall_escalation_%": overall_escal,
        "train_escalation_%": train_escal,
        "post_escalation_%": post_escal,
        "train_shocks_per_cow_per_day": train_rate,
        "post_shocks_per_cow_per_day": post_rate,
        "overall_shocks_per_cow_per_day": overall_rate,
        "shock_events": len(shock_log),
        "cows_with_≥1_shock": int(len({ev["cow"] for ev in shock_log})),
        "seed": seed
    }

    # --- Video ---
    if cfg.MAKE_VIDEO:
        fig, ax = plt.subplots(figsize=(cfg.FIGSIZE, cfg.FIGSIZE))
        scat = ax.scatter([], [], s=25)
        scat_cue   = ax.scatter([], [], s=250, facecolors='none', edgecolors='gold', linewidths=1.8)
        scat_shock = ax.scatter([], [], s=80, marker='x', c='magenta', linewidths=2.0)

        texts = [ax.text(0, 0, "", fontsize=6) for _ in range(cfg.NUM_COWS)]
        count_text = ax.text(cfg.FIELD_SIZE / 2, cfg.FIELD_SIZE + 6, "", fontsize=10, color='black', ha='center',
                             bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))

        # Patches
        for gx, gy, w, h in cfg.grazing_patches:
            ax.add_patch(patches.Rectangle((gx, gy), w, h, color='lightgreen', alpha=0.3))
        fence_color = (1, 0, 0, 0.1)
        ax.add_patch(plt.Rectangle((0, 0), cfg.FENCE_TRIGGER, cfg.FIELD_SIZE, color=fence_color))
        ax.add_patch(plt.Rectangle((cfg.FIELD_SIZE - cfg.FENCE_TRIGGER, 0), cfg.FENCE_TRIGGER, cfg.FIELD_SIZE, color=fence_color))
        ax.add_patch(plt.Rectangle((0, 0), cfg.FIELD_SIZE, cfg.FENCE_TRIGGER, color=fence_color))
        ax.add_patch(plt.Rectangle((0, cfg.FIELD_SIZE - cfg.FENCE_TRIGGER), cfg.FIELD_SIZE, cfg.FENCE_TRIGGER, color=fence_color))

        legend_patches = [
            Patch(color='green', label='Grazing'),
            Patch(color='blue', label='Walking'),
            Patch(color='red', label='Reacting'),
        ]
        cue_handle   = Line2D([0], [0], marker='o', linestyle='None', markerfacecolor='none',
                              markeredgecolor='gold', markeredgewidth=1.8, markersize=10, label='Audio cue')
        shock_handle = Line2D([0], [0], marker='x', linestyle='None', color='magenta',
                              markeredgewidth=2.0, markersize=8, label='Electric shock')
        ax.legend(handles=legend_patches + [cue_handle, shock_handle], loc='lower left')
        ax.set_xlim(0, cfg.FIELD_SIZE)
        ax.set_ylim(0, cfg.FIELD_SIZE + 10)
        ax.set_aspect('equal')
        ax.set_xticks([]); ax.set_yticks([])
        ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)

        def update(frame):
            scat.set_offsets(trajectory[frame])
            scat.set_color(state_colors[frame])
            cue_pts = cue_marker_positions_per_frame[frame]
            shock_pts = shock_marker_positions_per_frame[frame]
            if cue_pts.size:
                scat_cue.set_offsets(cue_pts); scat_cue.set_visible(True)
            else:
                scat_cue.set_offsets(np.empty((0, 2))); scat_cue.set_visible(False)
            if shock_pts.size:
                scat_shock.set_offsets(shock_pts); scat_shock.set_visible(True)
            else:
                scat_shock.set_offsets(np.empty((0, 2))); scat_shock.set_visible(False)
            for i, text in enumerate(texts):
                text.set_position(trajectory[frame][i])
                text.set_text(cow_labels[frame][i])
            g = np.sum(np.array(state_colors[frame]) == 'green')
            b = np.sum(np.array(state_colors[frame]) == 'blue')
            r = np.sum(np.array(state_colors[frame]) == 'red')
            count_text.set_text(f"Grazing: {g} | Walking: {b} | Reacting: {r}")
            return scat, scat_cue, scat_shock, *texts, count_text

        ani = animation.FuncAnimation(fig, update, frames=cfg.STEPS, interval=40)

        # High-quality writer (H.264 + higher bitrate + DPI)
        writer = animation.FFMpegWriter(
            fps=cfg.VIDEO_FPS,
            codec="libx264",
            bitrate=cfg.BITRATE,
            extra_args=["-pix_fmt", "yuv420p"]
        )
        ani.save(cfg.FILENAME, writer=writer, dpi=cfg.DPI)
        plt.close(fig)

    return metrics, shock_log


# -------------- Scenarios --------------

def make_scenarios(baseline: SimConfig):
    scenarios = {}

    # Baseline
    base = deepcopy(baseline)
    scenarios["baseline"] = base

    # 1) Post cue-only (very low post escalation)
    cue_only = deepcopy(baseline)
    cue_only.POST_ESCALATE_FRAC_MIN = 0.00
    cue_only.POST_ESCALATE_FRAC_MAX = 0.05
    cue_only.ESC_INIT_POST = 0.05
    cue_only.FILENAME = "sim3_cue_only_post.mp4"
    scenarios["cue_only_post"] = cue_only

    # 2) Low-salience audio (noisier environment)
    low_sal = deepcopy(baseline)
    low_sal.A = 65.0
    low_sal.s = 0.2
    low_sal.FILENAME = "sim3_low_salience.mp4"
    scenarios["low_salience"] = low_sal

    # 3) Temptation near fence: add a patch inside band; soften post probes
    tempt = deepcopy(baseline)
    patches_list = list(tempt.grazing_patches)
    patches_list.append((4, 30, 12, 20))  # near left warning band
    tempt.grazing_patches = tuple(patches_list)
    tempt.POST_OUTWARD_BIAS_NEAREST = 0.05
    tempt.POST_OUTWARD_BIAS_CENTER  = 0.05
    tempt.EDGE_PROBE_PUSH = 0.20
    tempt.FILENAME = "sim3_temptation_edge.mp4"
    scenarios["temptation_edge"] = tempt

    # 4) Social bonds removed (independent probes)
    nobonds = deepcopy(baseline)
    nobonds.FILENAME = "sim3_no_bonds.mp4"
    scenarios["no_bonds"] = nobonds  # We’ll zero the social matrix inside run if we want; or note in text.

    # 5) Narrow warning band (trade-off)
    narrow = deepcopy(baseline)
    narrow.FENCE_TRIGGER = 10.0
    narrow.FILENAME = "sim3_narrow_band.mp4"
    scenarios["narrow_band"] = narrow

    return scenarios


# -------------- Runner --------------

if __name__ == "__main__":
    # Master switches
    MAKE_VIDEOS   = True                 # set False to skip all videos
    VIDEOS_FOR    = {"baseline"}         # which scenarios should save videos
    SEEDS         = [42, 43, 44, 45, 46] # seed sweep for robust stats
    VIDEO_SEED    = 42                   # only save the video for this seed
    SAVE_ALL_SEEDS = False               # set True if you want a video per seed

    # Baseline config matching your latest code and metrics scale
    baseline_cfg = SimConfig(
        MAKE_VIDEO=False,        # default off; we selectively enable below
        WARMUP_STEPS=0,          # set to 6 if you want to avoid the step-4 shock cluster
        FILENAME="sim3_baseline.mp4"
    )

    scenarios = make_scenarios(baseline_cfg)

    all_results = {}

    for name, cfg in scenarios.items():
        print(f"\n=== Scenario: {name} ===")
        stats = []
        for sd in SEEDS:
            cfg_run = deepcopy(cfg)

            # Only save the video for VIDEO_SEED (or for every seed if SAVE_ALL_SEEDS=True)
            cfg_run.MAKE_VIDEO = (
                MAKE_VIDEOS
                and (name in VIDEOS_FOR)
                and (SAVE_ALL_SEEDS or sd == VIDEO_SEED)
            )

            # If saving multiple seeds, append the seed to the filename
            if cfg_run.MAKE_VIDEO and SAVE_ALL_SEEDS:
                root = cfg_run.FILENAME.rsplit(".", 1)[0]
                cfg_run.FILENAME = f"{root}_seed{sd}.mp4"

            metrics, shock_log = run_sim(cfg_run, seed=sd)
            stats.append(metrics)

            print(f" seed {sd}: cues={metrics['total_cues']}, shocks={metrics['total_shocks']} "
                  f"(train={metrics['train_shocks']}, post={metrics['post_shocks']}), "
                  f"esc%={metrics['overall_escalation_%']:.1f}, "
                  f"post s/cow/day={metrics['post_shocks_per_cow_per_day']:.3f}")

        # Aggregate
        def agg(key):
            arr = np.array([m[key] for m in stats], dtype=float)
            return float(np.median(arr)), float(np.percentile(arr, 25)), float(np.percentile(arr, 75))

        keys_report = [
            "total_cues", "total_shocks", "train_shocks", "post_shocks",
            "overall_escalation_%", "train_escalation_%", "post_escalation_%",
            "train_shocks_per_cow_per_day", "post_shocks_per_cow_per_day",
            "cows_with_≥1_shock"
        ]
        summary = {k: agg(k) for k in keys_report}
        all_results[name] = summary

        print(" --- Median [IQR] ---")
        for k in keys_report:
            med, q1, q3 = summary[k]
            if "percent" in k or k.endswith("%"):
                print(f" {k}: {med:.1f}% [{q1:.1f}, {q3:.1f}]")
            elif "per_cow_per_day" in k:
                print(f" {k}: {med:.3f} [{q1:.3f}, {q3:.3f}]")
            else:
                print(f" {k}: {med:.1f} [{q1:.1f}, {q3:.1f}]")

    print("\nDone. Videos (if enabled) were saved with H.264, ~9 Mbps, dpi=200.")

# --- quick_render_other_scenarios.py (run this after your main script) ---
from copy import deepcopy

# Use the same helpers and config from your script
# (assumes SimConfig, make_scenarios, run_sim are already defined in memory;
# if they're in a module, import them instead)

VIDEO_SEED = 42
TO_RENDER = ["cue_only_post", "low_salience", "temptation_edge", "no_bonds", "narrow_band"]  # pick any subset

# Start from your baseline but make sure video is ON; filenames will be set per-scenario below
base_cfg = SimConfig(MAKE_VIDEO=True, WARMUP_STEPS=0)

scenarios = make_scenarios(base_cfg)

for name in TO_RENDER:
    cfg = deepcopy(scenarios[name])
    # ensure video is on and give each a distinct filename
    cfg.MAKE_VIDEO = True
    root = cfg.FILENAME.rsplit(".", 1)[0]
    cfg.FILENAME = f"{root}_seed{VIDEO_SEED}.mp4"
    print(f"\nRendering {name} → {cfg.FILENAME}")
    metrics, _ = run_sim(cfg, seed=VIDEO_SEED)
    print(f"  cues={metrics['total_cues']}, shocks={metrics['total_shocks']} "
          f"(train={metrics['train_shocks']}, post={metrics['post_shocks']})")

import numpy as np
import matplotlib.pyplot as plt

# Define colorblind-safe palette (True row)
COLORS = {
    "train": "#E7298A",   # magenta
    "post": "#66A61E",    # green
    "audio": "#E7298A",   # same as train
    "shock": "#66A61E",   # same as post
}

# === Enter your median and IQR numbers (from your console output) ===
metrics = {
    "baseline": {"train_s_per_day": (0.611, 0.611, 0.944), "post_s_per_day": (0.119, 0.095, 0.143), "esc_percent": (36.2, 32.4, 37.9)},
    "cue_only_post": {"train_s_per_day": (0.611, 0.611, 0.944), "post_s_per_day": (0.000, 0.000, 0.000), "esc_percent": (24.3, 23.4, 29.3)},
    "low_salience": {"train_s_per_day": (0.667, 0.667, 0.889), "post_s_per_day": (0.095, 0.071, 0.190), "esc_percent": (38.2, 37.7, 38.5)},
    "temptation_edge": {"train_s_per_day": (0.833, 0.611, 0.889), "post_s_per_day": (0.119, 0.095, 0.143), "esc_percent": (40.5, 36.5, 42.3)},
    "no_bonds": {"train_s_per_day": (0.611, 0.611, 0.944), "post_s_per_day": (0.119, 0.095, 0.143), "esc_percent": (36.2, 32.4, 37.9)},
    "narrow_band": {"train_s_per_day": (0.278, 0.222, 0.278), "post_s_per_day": (0.024, 0.000, 0.048), "esc_percent": (40.0, 37.5, 53.3)},
}

scenarios = list(metrics.keys())

# ---------- Figure A: shocks·cow⁻¹·day⁻¹ (training vs post) ----------
train_med = [metrics[s]["train_s_per_day"][0] for s in scenarios]
train_q1  = [metrics[s]["train_s_per_day"][1] for s in scenarios]
train_q3  = [metrics[s]["train_s_per_day"][2] for s in scenarios]
train_err = np.array([[m - q1, q3 - m] for m, q1, q3 in zip(train_med, train_q1, train_q3)]).T

post_med = [metrics[s]["post_s_per_day"][0] for s in scenarios]
post_q1  = [metrics[s]["post_s_per_day"][1] for s in scenarios]
post_q3  = [metrics[s]["post_s_per_day"][2] for s in scenarios]
post_err = np.array([[m - q1, q3 - m] for m, q1, q3 in zip(post_med, post_q1, post_q3)]).T

x = np.arange(len(scenarios))
w = 0.38

plt.figure(figsize=(9, 4.5))
plt.bar(x - w/2, train_med, width=w, yerr=train_err, capsize=4,
        label="Training", color=COLORS["train"])
plt.bar(x + w/2, post_med,  width=w, yerr=post_err,  capsize=4,
        label="Post-learning", color=COLORS["post"])

plt.xticks(x, scenarios, rotation=20, ha="right", fontsize=12)
plt.ylabel("Shocks per cow per day (median, IQR)", fontsize=15)
plt.legend(fontsize=13)
plt.yticks(fontsize=12)

plt.tight_layout()
plt.savefig("fig_shocks_per_cow_per_day.png", dpi=600, bbox_inches="tight")
plt.show()

# ---------- Figure B: overall escalation % ----------
esc_med = [metrics[s]["esc_percent"][0] for s in scenarios]
esc_q1  = [metrics[s]["esc_percent"][1] for s in scenarios]
esc_q3  = [metrics[s]["esc_percent"][2] for s in scenarios]
esc_err = np.array([[m - q1, q3 - m] for m, q1, q3 in zip(esc_med, esc_q1, esc_q3)]).T

plt.figure(figsize=(9.2, 4.6))
plt.bar(x, esc_med, yerr=esc_err, capsize=4,
        color=COLORS["audio"], edgecolor="black", linewidth=0.9)

plt.xticks(x, scenarios, rotation=20, ha="right", fontsize=12)
plt.ylabel("Overall escalation (%) (median, IQR)", fontsize=15)
plt.yticks(fontsize=12)
plt.grid(axis="y", linestyle=":", linewidth=0.7, alpha=0.6)

plt.subplots_adjust(bottom=0.2, left=0.15, right=0.98, top=0.98)
plt.savefig("fig_escalation_percent.png", dpi=600, bbox_inches="tight")
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# -------- palette (from your swatch) --------
COL_GRAY   = "#cecece"
COL_PURPLE = "#a559aa"  # Training
COL_TEAL   = "#59a89c"  # Post-learning
COL_GOLD   = "#f0c571"  # Audio-like fill
COL_RED    = "#e02b35"  # Shock-like edge
COL_NAVY   = "#082a54"  # For error bars
COL_MAGENTA = "#FF00FF" # Shock-like edge (magenta)

# -------- typography (bigger labels & ticks) --------
plt.rcParams.update({
    "axes.labelsize": 13,
    "xtick.labelsize": 13,
    "ytick.labelsize": 13,
    "legend.fontsize": 13,
    "axes.titlesize": 16,   # we won’t use titles, but set anyway
})

# === Enter your median and IQR numbers ===
metrics = {
    "baseline":        {"train_s_per_day": (0.611, 0.611, 0.944), "post_s_per_day": (0.119, 0.095, 0.143), "esc_percent": (36.2, 32.4, 37.9)},
    "cue_only_post":   {"train_s_per_day": (0.611, 0.611, 0.944), "post_s_per_day": (0.000, 0.000, 0.000), "esc_percent": (24.3, 23.4, 29.3)},
    "low_salience":    {"train_s_per_day": (0.667, 0.667, 0.889), "post_s_per_day": (0.095, 0.071, 0.190), "esc_percent": (38.2, 37.7, 38.5)},
    "temptation_edge": {"train_s_per_day": (0.833, 0.611, 0.889), "post_s_per_day": (0.119, 0.095, 0.143), "esc_percent": (40.5, 36.5, 42.3)},
    "no_bonds":        {"train_s_per_day": (0.611, 0.611, 0.944), "post_s_per_day": (0.119, 0.095, 0.143), "esc_percent": (36.2, 32.4, 37.9)},
    "narrow_band":     {"train_s_per_day": (0.278, 0.222, 0.278), "post_s_per_day": (0.024, 0.000, 0.048), "esc_percent": (40.0, 37.5, 53.3)},
}

scenarios = list(metrics.keys())
xlabels = ["baseline", "cue_only_post", "low_salience",
           "temptation_edge", "no_bonds", "narrow_band"]

# convenience to build asymmetric IQR error bars
def err_from_med_qs(meds, q1s, q3s):
    return np.vstack([np.array(meds) - np.array(q1s),
                      np.array(q3s) - np.array(meds)])

# ---------- Figure A: shocks·cow⁻¹·day⁻¹ (training vs post) ----------
train_med = [metrics[s]["train_s_per_day"][0] for s in scenarios]
train_q1  = [metrics[s]["train_s_per_day"][1] for s in scenarios]
train_q3  = [metrics[s]["train_s_per_day"][2] for s in scenarios]
train_err = err_from_med_qs(train_med, train_q1, train_q3)

post_med = [metrics[s]["post_s_per_day"][0] for s in scenarios]
post_q1  = [metrics[s]["post_s_per_day"][1] for s in scenarios]
post_q3  = [metrics[s]["post_s_per_day"][2] for s in scenarios]
post_err = err_from_med_qs(post_med, post_q1, post_q3)

x = np.arange(len(scenarios))
w = 0.38
# err_kw = dict(ecolor=COL_NAVY, elinewidth=1.8, capsize=4, capthick=1.8) # Removed

fig, ax = plt.subplots(figsize=(9.2, 4.8))
ax.bar(x - w/2, train_med, width=w, yerr=train_err, # Removed **err_kw
       error_kw=dict(ecolor=COL_NAVY, elinewidth=1.8, capsize=4, capthick=1.8), # Added
       color=COL_PURPLE, edgecolor="none", label="Training")
ax.bar(x + w/2, post_med,  width=w, yerr=post_err,  # Removed **err_kw
       error_kw=dict(ecolor=COL_NAVY, elinewidth=1.8, capsize=4, capthick=1.8), # Added
       color=COL_TEAL, edgecolor="none", label="Post-learning")

ax.set_xticks(x); ax.set_xticklabels(xlabels, rotation=20, ha="right")
ax.set_ylabel("Shocks per cow per day (median, IQR)")
ax.legend(frameon=False)
# margins to prevent y-label cutoff
fig.subplots_adjust(left=0.16, bottom=0.25, right=0.99, top=0.99)
fig.savefig("fig_shocks_per_cow_per_day.png", dpi=600, bbox_inches="tight")
plt.show()

# ---------- Figure B: overall escalation % ----------
esc_med = [metrics[s]["esc_percent"][0] for s in scenarios]
esc_q1  = [metrics[s]["esc_percent"][1] for s in scenarios]
esc_q3  = [metrics[s]["esc_percent"][2] for s in scenarios]
esc_err = err_from_med_qs(esc_med, esc_q1, esc_q3)

fig, ax = plt.subplots(figsize=(9.2, 4.6))
ax.bar(x, esc_med, yerr=esc_err, # Removed **err_kw
       error_kw=dict(ecolor=COL_NAVY, elinewidth=1.8, capsize=4, capthick=1.8), # Added
       color=COL_GOLD, edgecolor=COL_MAGENTA, linewidth=1.4)
ax.set_xticks(x); ax.set_xticklabels(xlabels, rotation=18, ha="right")
ax.set_ylabel("Overall escalation (%) (median, IQR)")
ax.grid(False)  # remove horizontal grid lines
fig.subplots_adjust(left=0.16, bottom=0.25, right=0.99, top=0.99)
fig.savefig("fig_escalation_percent.png", dpi=600, bbox_inches="tight")
plt.show()

